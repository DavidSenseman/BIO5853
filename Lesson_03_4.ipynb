{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DavidSenseman/BIO5853/blob/main/Lesson_03_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyDfl-kuJtqx"
      },
      "source": [
        "---------------------------\n",
        "**COPYRIGHT NOTICE:** This Jupyterlab Notebook is a Derivative work of [Jeff Heaton](https://github.com/jeffheaton) licensed under the Apache License, Version 2.0 (the \"License\"); You may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
        "\n",
        "> [http://www.apache.org/licenses/LICENSE-2.0](http://www.apache.org/licenses/LICENSE-2.0)\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.\n",
        "\n",
        "------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5BPQI8wJtqy"
      },
      "source": [
        "# **BIO 5853: Biostatistics**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ja7XXUWNJtqy"
      },
      "source": [
        "##### **Module 3: Inference**\n",
        "\n",
        "* Instructor: [David Senseman](mailto:David.Senseman@utsa.edu), [Department of Integrative Biology](https://sciences.utsa.edu/integrative-biology/), [UTSA](https://www.utsa.edu/)\n",
        "\n",
        "\n",
        "### Module 3 Material\n",
        "\n",
        "* Part 3.1: Confidence Intervals\n",
        "* Part 3.2: Hypothesis Testing\n",
        "* Part 3.3: Comparison of Two Means\n",
        "* **Part 3.4: Analysis of Variance (ANOVA)**\n",
        "* Part 3.5: Nonparametric Methods\n",
        "* Part 3.6: Inference on Proportions\n",
        "* Part 3.7: Contingency Tables\n",
        "* Part 3.8: Correlation\n",
        "* Part 3.9: Simple Linear Regression\n",
        "* Part 3.10: Multiple Linear Regression\n",
        "* Part 3.11: Logistic Regression\n",
        "* Part 3.12: Survival Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKQylnEiLDUM"
      },
      "source": [
        "## Google CoLab Instructions\n",
        "\n",
        "The following code ensures that Google CoLab is running the correct version of TensorFlow.\n",
        "  Running the following code will map your GDrive to ```/content/drive```."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "seXFCYH4LDUM"
      },
      "outputs": [],
      "source": [
        "# YOU MUST RUN THIS CELL FIRST\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    from google.colab import auth\n",
        "    auth.authenticate_user()\n",
        "    COLAB = True\n",
        "    print(\"Note: using Google CoLab\")\n",
        "    %tensorflow_version 2.x\n",
        "    import requests\n",
        "    gcloud_token = !gcloud auth print-access-token\n",
        "    gcloud_tokeninfo = requests.get('https://www.googleapis.com/oauth2/v3/tokeninfo?access_token=' + gcloud_token[0]).json()\n",
        "    print(gcloud_tokeninfo['email'])\n",
        "except:\n",
        "    print(\"Note: not using Google CoLab\")\n",
        "    COLAB = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFYTYDo-Jtq0"
      },
      "source": [
        "# **Part 3.4: Analysis of Variance (ANOVA)**\n",
        "\n",
        "**_Analysis of Variance (ANOVA)_** is a statistical technique used to determine if there are significant differences between the means of three or more groups. It essentially helps to test hypotheses about whether the means of different groups are equal or not.\n",
        "\n",
        "#### **Key Concepts of ANOVA:**\n",
        "1. **Hypothesis Testing:** ANOVA tests the null hypothesis that all group means are equal against the alternative hypothesis that at least one group mean is different.\n",
        "2. **_F_ -Statistic:** The test uses the _F_ -statistic, which is a ratio of the variance between the groups to the variance within the groups.\n",
        "3. **Types of ANOVA:**\n",
        "- * **One-Way ANOVA:** Tests the effect of a single factor on a response variable.\n",
        "- * **Two-Way ANOVA:** Tests the effect of two factors and their interaction on a response variable.\n",
        "\n",
        "#### **Importance in Biostatistics:**\n",
        "\n",
        "1. **Comparing Multiple Groups:** ANOVA is crucial in biostatistics for comparing the means of multiple groups simultaneously, which is common in medical and biological research.\n",
        "2. **Eliminating Confounding Factors:** It helps to control for confounding variables, ensuring that the observed differences are due to the factors being studied.\n",
        "3. **Validity of Results:** By using ANOVA, researchers can obtain more reliable and valid results, reducing bias in their studies.\n",
        "4. **Efficiency:** Instead of performing multiple t-tests, which increases the risk of Type I error, ANOVA provides a more efficient and accurate way to compare multiple groups."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-4x2sWXJtq0"
      },
      "source": [
        "## **One-Way Analysis of Variance**\n",
        "\n",
        "When the groups for which the means are being compared represent the classes defined by a single  categorical variable, we use one-way analysis of variance.  \n",
        "\n",
        "### **The Problem**  \n",
        "\n",
        "Suppose you want to examine data from a study that investigated the effects of carbon monoxide exposure on patients with coronary artery disease by subjecting them to a series of exercise tests. The males involved in this study were recruited from three different medical centers — the Johns Hopkins University School of Medicine,  the Rancho Los Amigos Medical Center, and the St. Louis University School of Medicine.\n",
        "\n",
        "Before  combining the subjects into one large group to conduct the analysis, we should have first examined  some baseline characteristics to ensure that the individuals from different centers were in fact comparable. One characteristic that we might wish to consider is pulmonary function at the start of the study. If the subjects from one medical center begin with measures of forced expiratory volume in 1 second (fev1) that are much larger – or much smaller – than those from the other centers, the results of the analysis may be affected. Therefore, given that the populations of patients in the three centers have mean baseline fev1 measurements $\\mu_1$, $\\mu_2$, and $\\mu_3$ respectively, we would like to test the null hypothesis thatthe population means are identical. This may be expressed as  \n",
        "\n",
        "$$ H_0: \\mu_1 = \\mu_2 = \\mu_3 $$\n",
        "\n",
        "Note that the populations being compared are defined by the three classes of the categorical variable  medical center. The alternative hypothesis is that at least one of the population means differs from one of the others.  In general, we are interested in comparing the means of k different populations. Suppose that the _k_ populations are independent and normally distributed.\n",
        "\n",
        "We begin by drawing a random sample  of size $n_1$ from the normal population with mean $\\mu_1$ and standard deviation $\\sigma_1$. The mean of this sample is denoted by $\\bar{x}_1$ and its standard deviation by $s_1$. Similarly, we select a random sample of size $n_2$ from the normal population with mean $\\mu_2$ and standard deviation $\\sigma_2$ σ2, and so on for the remaining populations. The numbers of observations in each sample need not be the same.  \n",
        "\n",
        "![____](https://biologicslab.co/BIO5853/images/module_03/lesson_03_4_image01.png)\n",
        "\n",
        "Pagano, Marcello; Gauvreau, Kimberlee; Mattie, Heather. Principles of Biostatistics (p. 280). CRC Press. Kindle Edition."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9rvw1NOJtq1"
      },
      "source": [
        "## **Datasets for this Lesson**\n",
        "\n",
        "In this lesson we will be using 3 datasets that we need to read from the course file server. The first dataset contains the fev1 values that are used in the \"**The Problem**\" outlined above. Two additional datasets will also be used in this lesson."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lt7NNtIcJtq1"
      },
      "source": [
        "### Example 1: Read Datafile\n",
        "\n",
        "The code in the cell below uses the Pandas function `pd.read_csv(filename)` to read the data file `centers_fev1.csv` stored on the course HTTPS server https://biologicslab.co. As the file is read, it is stored in a Pandas DataFrame called `fvDF`.\n",
        "\n",
        "This file contains the data for **The Problem** decribed in the preceeding text cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edYL4q9oJtq1"
      },
      "outputs": [],
      "source": [
        "# Example 1: Read datafile\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Read datafile and create DataFrame\n",
        "fvDF = pd.read_csv(\n",
        "    \"https://biologicslab.co/BIO5853/data/centers_fev1.csv\",\n",
        "    index_col=0,\n",
        "    sep=',',\n",
        "    na_values=['NA','?'])\n",
        "\n",
        "# Set max rows and max columns\n",
        "pd.set_option('display.max_rows', 6)\n",
        "pd.set_option('display.max_columns', 4)\n",
        "\n",
        "# Display DataFrame\n",
        "display(fvDF)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3VLFliiJtq1"
      },
      "source": [
        "If your code is correct, you should see the following output:\n",
        "\n",
        "![____](https://biologicslab.co/BIO5853/images/module_03/lesson_03_4_image11.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWSDK_z2Jtq2"
      },
      "source": [
        "Our new DataFrame `fvDF` has total of 60 records of fev1 values in the column **fev1**. This is the to the total volume of air that is forcibly inhaled or exhaled from the lungs within one minute. This measurement is crucial in respiratory physiology as it helps assess lung function and ventilation efficiency.\n",
        "\n",
        "![____](https://biologicslab.co/BIO5853/images/module_03/LungVolumes.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKrBarx1Jtq2"
      },
      "source": [
        "### **Exercise 1A: Read Datafile**\n",
        "\n",
        "In the cell below, use the Pandas function `pd.read_csv(filename)` to read a data file called `Cushings.csv` stored on the course HTTPS server https://biologicslab.co. As the file is read, store in a Pandas DataFrame called `cushDF`.\n",
        "\n",
        "#### **Data Description**\n",
        "\n",
        "Cushing’s syndrome is a hormone disorder associated with high level of cortisol secreted by the adrenal gland. The Cushings data set includes 27 observations (n = 27). For each individual in the sample, the urinary excretion rates of two steroid metabolites are recorded. These are urinary excretion rate (mg/24 hr) of Tetrahydrocortisone (`TCort`) and urinary excretion rate (mg/24 hr) of Pregnanetriol (`PregN`). The Type variable in the data set shows the underlying type of syndrome, which can be one of four categories: adenoma (a), bilateral hyperplasia (b), carcinoma (c), and unknown (u).\n",
        "\n",
        "_Code Hints:_\n",
        "\n",
        "1. You will need to comment out the following line:\n",
        "~~~text\n",
        "#    index_col=0,\n",
        "~~~\n",
        "Except for this change, you can just reuse the code in Example 1 'as is', after you change the name of the datafile and the DataFrame.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JDm1xF62Jtq2"
      },
      "outputs": [],
      "source": [
        "# Insert your code for Exercise 1 here\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ep7Xidd9Jtq2"
      },
      "source": [
        "If your code is correct, you should see the following output:\n",
        "\n",
        "![____](https://biologicslab.co/BIO5853/images/module_03/lesson_03_4_image12.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HG32RNbkJtq2"
      },
      "source": [
        "### **Exercise 1B: Read Datafile**\n",
        "\n",
        "In the cell below, use the Pandas function `pd.read_csv(filename)` to read a data file called `genotype.csv` stored on the course HTTPS server https://biologicslab.co. As the file is read, store in a Pandas DataFrame called `genoDF`.\n",
        "\n",
        "#### **Data Description**\n",
        "\n",
        "Data from a foster feeding experiment with rat mothers and litters of four different genotypes: A, B, I and J. Rat litters were separated from their natural mothers at birth and given to foster mothers to rear.\n",
        "\n",
        "The data frame has the following components:\n",
        "* **Litter:** genotype of the litter.\n",
        "* **Mother:** genotype of the foster mother.\n",
        "* **Wt:** Litter average weight gain of the litter, in grams at age 28 days. (The source states that the\n",
        "within-litter variability is negligible.)\n",
        "\n",
        "_Code Hints:_\n",
        "\n",
        "1. As in **Exercise 1A**, you will need to comment out the following line:\n",
        "~~~text\n",
        "#    index_col=0,\n",
        "~~~\n",
        "Except for this change, you can just reuse the code in Example 1 'as is', after you change the name of the datafile and the DataFrame.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lPyYQBnoJtq3"
      },
      "outputs": [],
      "source": [
        "# Insert your code for Exercise 1B here\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72PRBE1vJtq3"
      },
      "source": [
        "If your code is correct, you should see the following output:\n",
        "\n",
        "![____](https://biologicslab.co/BIO5853/images/module_03/lesson_03_4_image17.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLlzSFK2Jtq3"
      },
      "source": [
        "### Example 2A: Store DataFrame Values in Dictionary\n",
        "\n",
        "While it is ususally preferrable to peform statistical procedures (e.g. ANOVA) on data stored in a Pandas DataFrame, there are exceptions. Normally, each row in a DataFrame contains the data for an item such as an experimental animal, a test subject or a patient in a medical study. The different \"pieces\" of data belonging to that subject is located in one of the DataFrame columns. If you look at the output from Example 1, you see this:\n",
        "\n",
        "![____](https://biologicslab.co/BIO5853/images/module_03/lesson_03_4_image11.png)\n",
        "\n",
        "The column called `center` contains the numbers `1`, `2` and `3` which stand for the names of the three medical centers where the measurements were performed: `Johns Hopkins`, `Rancho Los Amigos` and `St. Louis`, respectively. One way to work with this kind of data, as illustrated in this example, is to create a Python **_dictionary_** called `fv1_dict` and store the fev1 measurements from each medical center separately as a Numpy array.\n",
        "\n",
        "_Code Description:_\n",
        "\n",
        "Since all of the fev1 measurements are in a single column called `fev1` we first need to specifically extract data from the column that belongs to a particular medical center. To do this we use something called a **_boolean mask_**. A boolean mask is a binary array or a boolean-valued array (containing `True` or `False` values) used to filter or select specific elements from another array based on certain conditions.\n",
        "Elements in the target array are selected if the corresponding element in the boolean mask is `True`.\n",
        "\n",
        "This is the code chunk that creates the boolean masks:\n",
        "~~~text\n",
        "# Generate masks\n",
        "center = [1, 2, 3]\n",
        "masks = {f'center_{t}': (fvDF.center == t) for t in center}\n",
        "~~~\n",
        "\n",
        "This code created 3 boolean masks called `center_1`, `center_2` and `center_3`. The mask `center_1` has boolean value `True` whenever the number in the column `center` was the number `1`, otherwise the boolean value is `False`.\n",
        "\n",
        "Once the 3 masks have been created, the next step is to use them to copy the data in the DataFrame `fvDF` from each center into a dictionary called `fev1_dict` using this code chunk:\n",
        "\n",
        "~~~text\n",
        "# Fill dictionary with values from the DataFrame\n",
        "for mask in masks:\n",
        "    fev1_dict[mask] = np.array(fvDF.fev1[globals()[mask]])\n",
        "~~~\n",
        "\n",
        "In a Python dictionary, there are `key:value` pairs. Right after it was created, the `keys` in the dictionary `fev1_dict` were `center_1`, `center_2` and `center_3`. While we know that `center_1` is `Johns Hopkins`, for example, it would be nice to change the key name to the name of the medical center. That was done with in the following code chunk:\n",
        "\n",
        "~~~text\n",
        "# Create function to rename dict keys\n",
        "def rename_key(dictionary, old_key, new_key):\n",
        "    if old_key in dictionary:\n",
        "        dictionary[new_key] = dictionary.pop(old_key)\n",
        "\n",
        "# Use function to rename keys\n",
        "rename_key(fev1_dict, 'center_1', 'Johns Hopkins')\n",
        "rename_key(fev1_dict, 'center_2', 'Rancho Los Amigos')\n",
        "rename_key(fev1_dict, 'center_3', 'St. Louis')\n",
        "~~~\n",
        "\n",
        "In the last part of the code cell, a `for loop` is used to print out all the `key:value` pairs in `fev1_dict`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Pt_BWxAJtq3"
      },
      "outputs": [],
      "source": [
        "# Example 2A: Store DataFrame Values in Dictionary\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Generate masks\n",
        "center = [1, 2, 3]\n",
        "masks = {f'center_{t}': (fvDF.center == t) for t in center}\n",
        "\n",
        "# If you need to access the masks\n",
        "center_1 = masks['center_1']\n",
        "center_2 = masks['center_2']\n",
        "center_3 = masks['center_3']\n",
        "\n",
        "# Initialize dictionary\n",
        "fev1_dict = {}\n",
        "\n",
        "# Fill dictionary with values from the DataFrame\n",
        "for mask in masks:\n",
        "    fev1_dict[mask] = np.array(fvDF.fev1[globals()[mask]])\n",
        "\n",
        "# Create function to rename dict keys\n",
        "def rename_key(dictionary, old_key, new_key):\n",
        "    if old_key in dictionary:\n",
        "        dictionary[new_key] = dictionary.pop(old_key)\n",
        "\n",
        "# Use function to rename keys\n",
        "rename_key(fev1_dict, 'center_1', 'Johns Hopkins')\n",
        "rename_key(fev1_dict, 'center_2', 'Rancho Los Amigos')\n",
        "rename_key(fev1_dict, 'center_3', 'St. Louis')\n",
        "\n",
        "# Print results\n",
        "print(\"----Key:Value pairs in fev1_dict ----------\")\n",
        "\n",
        "# Iterating over key-value pairs\n",
        "for key, value in fev1_dict.items():\n",
        "    print(f\"{key}: {value}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnQbX51XJtq4"
      },
      "source": [
        "If the code is correct, you should see the following output:\n",
        "\n",
        "~~~text\n",
        "----Key:Value pairs in fev1_dict ----------\n",
        "Johns Hopkins: [3.23000002 3.47000003 1.86000001 2.47000003 3.00999999 1.69000006\n",
        " 2.0999999  2.80999994 3.27999997 3.3599999  2.6099999  2.91000009\n",
        " 1.98000002 2.56999993 2.07999992 2.47000003 2.47000003 2.74000001\n",
        " 2.88000011 2.63000011 2.52999997]\n",
        "Rancho Los Amigos: [3.22000003 2.88000011 1.71000004 2.8900001  3.76999998 3.28999996\n",
        " 3.3900001  3.8599999  2.6400001  2.71000004 2.71000004 3.41000009\n",
        " 2.86999989 2.6099999  3.3900001  3.17000008]\n",
        "St. Louis: [2.78999996 3.22000003 2.25       2.98000002 2.47000003 2.76999998\n",
        " 2.95000005 3.55999994 2.88000011 2.63000011 3.38000011 3.06999993\n",
        " 2.80999994 3.17000008 2.23000002 2.19000006 4.05999994 1.98000002\n",
        " 2.80999994 2.8499999  2.43000007 3.20000005 3.52999997]\n",
        "~~~"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNm8x9bGJtq4"
      },
      "source": [
        "You should note that the number of `fev1` measurements are **_not_** the same between the 3 medical centers, with `St. Louis` having the largest number, and `Rancho Los Amigos` having the smallest number. In a typical DataFrame, each column as the same number of values. This data could be \"forced\" into a DataFrame, but it would be rather ugly. This is one of the main reasons that the `fev1` data is better stored in a Python dictionary instead of a DataFrame."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeGitOsuJtq4"
      },
      "source": [
        "### Example 2B: Store DataFrame Values in Dictionary\n",
        "\n",
        "The code in the cell below shows another example of how to store DataFrame values in a Python dictionary. Specifically, this example shows how to extract the data from the `TCort` column in the `cushDF` DataFrame and place this data in a new Python dictionary called `TCort_dict`. As in the preceding example, the code replaces the `key` names with the actual tumor type (e.g.`adenoma` instead of `type_a`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "XLt8XgvxJtq4"
      },
      "outputs": [],
      "source": [
        "# Example 2B: Store DataFrame Values in Dictionary\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Generate masks\n",
        "types = ['a', 'b', 'c', 'u']\n",
        "masks = {f'type_{t}': (cushDF.Type == t) for t in types}\n",
        "\n",
        "# If you need to access the masks\n",
        "type_a = masks['type_a']\n",
        "type_b = masks['type_b']\n",
        "type_c = masks['type_c']\n",
        "type_u = masks['type_u']\n",
        "\n",
        "# Initialize an empty array\n",
        "TCort_dict = {}\n",
        "\n",
        "# Fill empty array with TCort values from the DataFrame\n",
        "for mask in masks:\n",
        "    TCort_dict[mask] = np.array(cushDF.TCort[globals()[mask]])\n",
        "\n",
        "\n",
        "# Create function to rename dict keys\n",
        "def rename_key(dictionary, old_key, new_key):\n",
        "    if old_key in dictionary:\n",
        "        dictionary[new_key] = dictionary.pop(old_key)\n",
        "\n",
        "# Use function to rename keys\n",
        "rename_key(TCort_dict, 'type_a', 'adenoma')\n",
        "rename_key(TCort_dict, 'type_b', 'bilateral hyperplasia')\n",
        "rename_key(TCort_dict, 'type_c', 'carcinoma')\n",
        "rename_key(TCort_dict, 'type_u', 'unknown')\n",
        "\n",
        "# Print results\n",
        "print(\"----Key:Value pairs in TCort_dict ----------\")\n",
        "# Iterating over key-value pairs\n",
        "for key, value in TCort_dict.items():\n",
        "    print(f\"{key}: {value}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fdjIjPZJtq4"
      },
      "source": [
        "If the code is correct, you should see the following output:\n",
        "~~~text\n",
        "----Key:Value pairs in TCort_dict ----------\n",
        "adenoma: [3.1 3.  1.9 3.8 4.1 1.9]\n",
        "bilateral hyperplasia: [ 8.3  3.8  3.9  7.8  9.1 15.4  7.7  6.5  5.7 13.6]\n",
        "carcinoma: [10.2  9.2  9.6 53.8 15.8]\n",
        "unknown: [ 5.1 12.9 13.   2.6 30.  20.5]\n",
        "~~~"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7qETov7Jtq5"
      },
      "source": [
        "### **Exercise 2: Store DataFrame Values in Dictionary**\n",
        "\n",
        "In the cell below, write the Python code to extract the values for Pregnanetriol (`PregN`) from the DataFrame `cushDF` and store them in a new dictionary called `PregN_dict`. You can basically reuse the code in Example 2B after making the appropiate changes in the variable names."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "krZE5dZ8Jtq5"
      },
      "outputs": [],
      "source": [
        "# Insert your code for Exercise 2 here\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVCXT3x8Jtq5"
      },
      "source": [
        "If your code is correct, you should see the following output:\n",
        "\n",
        "~~~text\n",
        "----Key:Value pairs in PregN_dict ----------\n",
        "adenoma: [11.7   1.3   0.1   0.04  1.1   0.4 ]\n",
        "bilateral hyperplasia: [1.  0.2 0.6 1.2 0.6 3.6 1.6 0.4 0.4 1.6]\n",
        "carcinoma: [6.4 7.9 3.1 2.5 7.6]\n",
        "unknown: [0.4 5.  0.8 0.1 0.1 0.8]\n",
        "~~~"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QO5nDoTJtq5"
      },
      "source": [
        "### Example 3A: Print Summary Statistics\n",
        "\n",
        "The code in the cell below illustrates how to print out summary statistics for the forced ventilation (_fev_) data at each of the 3 medical centers in the DataFrame `fvDF`\n",
        "\n",
        "_Code Description:_\n",
        "\n",
        "The code uses a custom function called `compute_stats(data)` to compute the statistics. The advantage of this function is that it accepts a Python **_dictionary_** containing multiple numpy arrays as an argument. Here is the code for this custom function:\n",
        "\n",
        "~~~text\n",
        "# Function to compute summary stats\n",
        "def compute_stats(data):\n",
        "    stats = {}\n",
        "    for key, array in data.items():\n",
        "        mean = np.mean(array)\n",
        "        std_dev = np.std(array)\n",
        "        n = len(array)\n",
        "        min = np.min(array)\n",
        "        max = np.max(array)\n",
        "        stats[key] = {'count': n, 'mean': mean, 'std_dev': std_dev, 'min': min, 'max': max}\n",
        "    return stats\n",
        "~~~\n",
        "\n",
        "The only variable that needs to be changed is the name of the dictionary in the following code chunk:\n",
        "~~~text\n",
        "# Compute statistics\n",
        "stats = compute_stats(fev1_dict)\n",
        "~~~\n",
        "\n",
        "The information in the variable `stats` is converted into a DataFrame with the following code:\n",
        "\n",
        "~~~text\n",
        "# Create a DataFrame for better formatting\n",
        "stats_df = pd.DataFrame(stats).T\n",
        "~~~\n",
        "\n",
        "The dot \"T\" at the end of the line of code means to **_Transpose_** the data in the dictionary when creating the DataFrame. What this means is that the dictionary _keys_ (e.g. `Johns Hopkins`) become the row names, and the _values_ associated with each key becomes the data in that row."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "2EzzM6HxJtq5"
      },
      "outputs": [],
      "source": [
        "# Example 3A: Print Summary Statistics\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Function to compute summary stats\n",
        "def compute_stats(data):\n",
        "    stats = {}\n",
        "    for key, array in data.items():\n",
        "        mean = np.mean(array)\n",
        "        std_dev = np.std(array)\n",
        "        n = len(array)\n",
        "        min = np.min(array)\n",
        "        max = np.max(array)\n",
        "        stats[key] = {'count': n, 'mean': mean, 'std_dev': std_dev, 'min': min, 'max': max}\n",
        "    return stats\n",
        "\n",
        "# Compute statistics\n",
        "stats = compute_stats(fev1_dict)\n",
        "\n",
        "# Create a DataFrame for better formatting\n",
        "stats_df = pd.DataFrame(stats).T\n",
        "\n",
        "# Round the DataFrame to 2 decimal places\n",
        "stats_df = stats_df.round(2)\n",
        "\n",
        "# Set display options\n",
        "pd.set_option('display.max_rows', 8)\n",
        "pd.set_option('display.max_columns', 8)\n",
        "\n",
        "# Print header\n",
        "print(\"----Summary Statistics for fev1 data ---------------------\")\n",
        "\n",
        "# Print the DataFrame\n",
        "print(stats_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaql1n25Jtq5"
      },
      "source": [
        "If the code is correct, you should see the following output:\n",
        "\n",
        "~~~text\n",
        "----Summary Statistics for fev1 data ---------------------\n",
        "                   count  mean  std_dev   min   max\n",
        "Johns Hopkins       21.0  2.63     0.48  1.69  3.47\n",
        "Rancho Los Amigos   16.0  3.03     0.51  1.71  3.86\n",
        "St. Louis           23.0  2.88     0.49  1.98  4.06\n",
        "~~~"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yon0H04rJtq6"
      },
      "source": [
        "Except for some rounding errors, these are the same statistics for each medical center as shown at the bottom of **TABLE 12.1** on page 281.\n",
        "\n",
        "~~~text\n",
        "  Johns Hopkins       Rancho Los Amigos        St. Louis\n",
        "    n1 = 21               n2 = 16               n3 = 23  \n",
        "x1 = 2.63 liters      x2 = 3.03 liters     x3 = 2.88 liters  \n",
        "s1 = 0.496 liters     s2 = 0.523 liters    s3 = 0.498 liters\n",
        "~~~"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yi2rfSSIJtq6"
      },
      "source": [
        "### **Exercise 3A: Print Summary Statistics**\n",
        "\n",
        "In the cell below, write the Python code to print out summary statistics for TCort data in the `TCort_dict`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "c6TCZ3EiJtq6"
      },
      "outputs": [],
      "source": [
        "# Insert your code for Exercise 3A here\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3r15gRGgJtq6"
      },
      "source": [
        "If your code if correct, you should see the following table:\n",
        "\n",
        "~~~text\n",
        "----Summary Statistics for TCort ---------------------------\n",
        "                       count   mean  std_dev  min   max\n",
        "adenoma                  6.0   2.97     0.84  1.9   4.1\n",
        "bilateral hyperplasia   10.0   8.18     3.59  3.8  15.4\n",
        "carcinoma                5.0  19.72    17.21  9.2  53.8\n",
        "unknown                  6.0  14.02     9.22  2.6  30.0\n",
        "~~~"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4e3hJbHtJtq6"
      },
      "source": [
        "### **Exercise 3B: Print Summary Statistics**\n",
        "\n",
        "In the cell below, write the Python code to print out summary statistics for PregN data in the `PregN_dict`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tWhVgjP6Jtq6"
      },
      "outputs": [],
      "source": [
        "# Insert your code for Exercise 3B here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vg9UenP8Jtq7"
      },
      "source": [
        "If your code if correct, you should see the following table:\n",
        "\n",
        "~~~text\n",
        "----Summary Statistics for NPreg ----------------------------\n",
        "                       count  mean  std_dev   min   max\n",
        "adenoma                  6.0  2.44     4.17  0.04  11.7\n",
        "bilateral hyperplasia   10.0  1.12     0.95  0.20   3.6\n",
        "carcinoma                5.0  5.50     2.27  2.50   7.9\n",
        "unknown                  6.0  1.20     1.72  0.10   5.0\n",
        "~~~"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXw1PrvOJtrA"
      },
      "source": [
        "### Example 4: Plot F-Distribution\n",
        "\n",
        "The code in the cell below illustrates how to recreate the _F_ distribution plot (**Figure 12.2**) on page 284 in your textbook. The code uses the `scipy.stats` function `f.pdf()` to generate the `y` values for a probability density function (pdf) using the following code chunk:\n",
        "~~~text\n",
        "# Calculate the F distribution probability density function (pdf)\n",
        "y = f.pdf(x, dfn, dfd)\n",
        "~~~\n",
        "\n",
        "When plotting the _F_ distribution, you must specify the degrees of freedon for both the numerator and the denominator. In the code below, this is done as shown in the following code chunk:\n",
        "\n",
        "~~~text\n",
        "# Define the degrees of freedom\n",
        "dfn = 4  # degrees of freedom for the numerator\n",
        "dfd = 2  # degrees of freedom for the denominator\n",
        "~~~~\n",
        "\n",
        "Other aspects of the code used for generating this x-y plot have been described in earlier lessons (e.g. Example 5 in Lesson_02_3).\n",
        "\n",
        "![____](https://biologicslab.co/BIO5853/images/module_03/lesson_03_4_image04.png)\n",
        "\n",
        "**FIGURE 12.2**  The _F_ distribution with 4 and 2 degrees of freedom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "7nTGON6XJtrB"
      },
      "outputs": [],
      "source": [
        "# Example 4: Plot F-distribution\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import f\n",
        "\n",
        "# Define the degrees of freedom\n",
        "dfn = 4  # degrees of freedom for the numerator\n",
        "dfd = 2  # degrees of freedom for the denominator\n",
        "\n",
        "# Set color\n",
        "color_1 = '#15365d' # Dark blue\n",
        "\n",
        "# Generate x values\n",
        "x = np.linspace(0, 20, 1000)\n",
        "\n",
        "# Calculate the F distribution probability density function (pdf)\n",
        "y = f.pdf(x, dfn, dfd)\n",
        "\n",
        "# Plot the F distribution\n",
        "plt.plot(x, y, color=color_1)\n",
        "\n",
        "# Ensure y-axis is not visible\n",
        "plt.gca().yaxis.set_visible(False)\n",
        "\n",
        "# Plot label\n",
        "plt.xlabel('x')\n",
        "\n",
        "# Plot text\n",
        "plt.text(-2.5, 0.60, 'f(x)', fontsize=12, style='italic')\n",
        "\n",
        "# Turn off grid\n",
        "plt.grid(False)\n",
        "\n",
        "# Show plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUKmSixpJtrB"
      },
      "source": [
        "If the code is correct, you should see the following table.\n",
        "\n",
        "![____](https://biologicslab.co/BIO5853/images/module_03/lesson_03_4_image05.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPAs09LMJtrB"
      },
      "source": [
        "**FIGURE 12.2**  The _F_ distribution with 4 and 2 degrees of freedom"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MI24vSQ7JtrB"
      },
      "source": [
        "### **Exercise 4: Plot F-distribution**\n",
        "\n",
        "In the cell below, write the Python code to generate a plot of the _F_ distribution with 2 degrees of freedom in the numerator and 4 degrees of freedom in the denominator.\n",
        "\n",
        "_Code Hints:_\n",
        "\n",
        "You can reuse the code in Example 4 after changing the degrees of freedom values. You will also have to change the location of the text that prints of the f(x) at the top left:\n",
        "\n",
        "~~~text\n",
        "# Plot text\n",
        "plt.text(-2.5, 1.0, 'f(x)', fontsize=12, style='italic')\n",
        "~~~"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "0LI8RTK7JtrB"
      },
      "outputs": [],
      "source": [
        "# Insert your code for Exercise 4 here\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlFGShUzJtrC"
      },
      "source": [
        "If your code is correct, you should see the following table.\n",
        "\n",
        "![____](https://biologicslab.co/BIO5853/images/module_03/lesson_03_4_image06.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3JWgfX2JtrC"
      },
      "source": [
        "The F distribution with 2 and 4 degrees of freedom"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzHhNP3MJtrC"
      },
      "source": [
        "## **Necessary Conditions for ANOVA**\n",
        "\n",
        "To use ANOVA (Analysis of Variance) effectively, several key assumptions must be met:\n",
        "\n",
        "* **Normality:** The data for each group should be approximately normally distributed. This can be checked using visual methods like histograms or Q-Q plots, or statistical tests like the Shapiro-Wilk test.\n",
        "* **Homogeneity of Variances:** The variances among the groups should be equal. This is also known as homoscedasticity. You can test this assumption using Levene’s test or Bartlett’s test.\n",
        "* **Independence:** The observations should be independent of each other. This means the data collected from one group should not influence the data from another group.\n",
        "\n",
        "On page 284, your textbook states:\n",
        "\n",
        ">Referring back to the fev1 data collected for patients from three different medical centers, we  are interested in testing\n",
        ">\n",
        "$$ H_0: \\mu_1 = \\mu_2 = \\mu_3,  $$\n",
        "\n",
        ">the null hypothesis that the mean forced expiratory volumes in 1 second for subjects from each of the three centers are identical. To begin, we verify that the fev1 measurements are approximately normally distributed. Based on the histograms shown in Figure 12.3, this appears to be a reasonable  assumption.\n",
        "\n",
        "\n",
        "![____](https://biologicslab.co/BIO5853/images/module_03/lesson_03_4_image07.png)\n",
        "\n",
        "**FIGURE 12.3** Histograms for measurements of forced expiratory volume in 1 second for subjects at three medical centers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6kqHHSmJtrC"
      },
      "source": [
        "### Example 5: Plot Histograms\n",
        "\n",
        "\n",
        "The code in the cell below shows to recreate **Figure 12.3** using Python.\n",
        "\n",
        "_Code Description:_\n",
        "\n",
        "This is a rather complex group plot with two histograms plotted on top row, and only one plotted in the lower row. Here is the code chunk for making a composite plot with two figures on the top row and two on the bottom row:\n",
        "~~~text\n",
        "# Create subplots\n",
        "fig, axs = plt.subplots(2, 2, figsize=(15, 10))\n",
        "~~~\n",
        "Since we only want 3 plots, the \"4th\" plot at the bottom right will be a dummy plot.\n",
        "\n",
        "Here is the code chunk that computes the histogram values from the data stored in the `fev1_dict` for one medical center (e.g. \"Johns Hopkins\")\n",
        "\n",
        "~~~text\n",
        "counts, _ = np.histogram(fev1_dict['Johns Hopkins'], bins=bins)\n",
        "~~~\n",
        "\n",
        "This line of Python code uses the `numpy.histogram` function to compute the histogram of the data stored in `fev1_dict['Johns Hopkins']`. Here is what it's doing:\n",
        "\n",
        "* **fev1_dict['Johns Hopkins']:** This accesses the data associated with the key `'Johns Hopkins'` in the dictionary `fev1_dict`.\n",
        "* **bins=bins:** This specifies the bin edges or the number of bins to use for the histogram. The variable `bins` is defined near the top of the code cell.\n",
        "* **np.histogram:** This function computes the histogram of the input data. It returns two values:\n",
        "- - **counts:** An array of the counts of data points in each bin.\n",
        "- - **_:** An array of the bin edges (not used in this case, hence the underscore _).\n",
        "\n",
        "So, the code calculates the frequency distribution of the data in `fev1_dict['Johns Hopkins']` and stores the counts of data points in each bin in the variable counts.\n",
        "\n",
        "Here is the code chunk that actually plots one bar chart using the \"histogram\" data:\n",
        "\n",
        "~~~text\n",
        "# Plot Johns Hopkins data\n",
        "counts, _ = np.histogram(fev1_dict['Johns Hopkins'], bins=bins)\n",
        "axs[0, 0].bar(bins[:-1], counts, width=bin_width, color=color_1)\n",
        "axs[0, 0].set_title('Johns Hopkins',fontsize=18)\n",
        "axs[0,0].tick_params(axis='x', labelsize=18)\n",
        "axs[0,0].tick_params(axis='y', labelsize=18)\n",
        "~~~\n",
        "\n",
        "Note that `axs[0,0]` represents the _top left_ chart, `axs[0,1]` represents the _top right_ chart,  `axs[1,0]` represents the _bottom left_ chart, and `axs[1,1]` represents the _bottom right_ chart."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "ENYi0fCCJtrC"
      },
      "outputs": [],
      "source": [
        "# Example 5A: Plot histograms\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Set color\n",
        "color_1 = '#15365d' # Dark blue\n",
        "\n",
        "# Set bin width\n",
        "bin_width = 0.485\n",
        "\n",
        "# Define bins for FEV values\n",
        "bins = np.arange(1.5, 4.5, 0.5)\n",
        "\n",
        "# Create subplots\n",
        "fig, axs = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# Plot Johns Hopkins data\n",
        "counts, _ = np.histogram(fev1_dict['Johns Hopkins'], bins=bins)\n",
        "axs[0, 0].bar(bins[:-1], counts, width=bin_width, color=color_1)\n",
        "axs[0, 0].set_title('Johns Hopkins',fontsize=18)\n",
        "axs[0,0].tick_params(axis='x', labelsize=18)\n",
        "axs[0,0].tick_params(axis='y', labelsize=18)\n",
        "\n",
        "# Plot Rancho Los Amigos data\n",
        "counts, _ = np.histogram(fev1_dict['Rancho Los Amigos'], bins=bins)\n",
        "axs[0, 1].bar(bins[:-1], counts, width=bin_width, color=color_1)\n",
        "axs[0, 1].set_title('Rancho Los Amigos', fontsize=18)\n",
        "axs[0,1].tick_params(axis='x', labelsize=18)\n",
        "axs[0,1].tick_params(axis='y', labelsize=18)\n",
        "\n",
        "# Plot St. Louis data\n",
        "counts, _ = np.histogram(fev1_dict['St. Louis'], bins=bins)\n",
        "axs[1, 0].bar(bins[:-1], counts, width=bin_width, color=color_1)\n",
        "axs[1, 0].set_title('St. Louis', fontsize=18)\n",
        "axs[1,0].tick_params(axis='x', labelsize=18)\n",
        "axs[1,0].tick_params(axis='y', labelsize=18)\n",
        "\n",
        "# Plot Dummy data\n",
        "counts=0\n",
        "axs[1, 1].bar(bins[:-1], counts, width=0.45, color=color_1)\n",
        "plt.axis('off')\n",
        "\n",
        "# Plot text\n",
        "plt.text(-0.10, -0.08, 'FEV in 1 second (liters)', fontsize=24)\n",
        "plt.text(-2.5, 0.05, 'Frequency', fontsize=24, rotation=90)\n",
        "\n",
        "# Adjust layout\n",
        "#plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-Fk66H0JtrC"
      },
      "source": [
        "If the code is correct, you should see the following table.\n",
        "\n",
        "![____](https://biologicslab.co/BIO5853/images/module_03/lesson_03_4_image08.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-7JfN_kJtrC"
      },
      "source": [
        "### Example 5B: Plot Histograms\n",
        "\n",
        "Since the Cushing's Syndrome data in the `cushDF` dataframe is significantly different from the `fev1` data, there are a number of changes that must be made in the Python code to create a composition histogram plot. The code in Example 5B, generates four histograms of the data stored in the dictionary `TCort_dict`.\n",
        "\n",
        "_Code Description:_\n",
        "\n",
        "The biggest change in the code between Example 5A and 5B has to do with the bin range. The bin range sets the limits of the x-axis. Here is the code that sets the bin range:\n",
        "\n",
        "~~~text\n",
        "# Define bins for TCort values\n",
        "bins = np.arange(1, 60, 2)\n",
        "~~~\n",
        "This line of code uses the Numpy function `np.arrange()` to generate a list of values, starting at `1` and ending at `60` with an increment of `2` between values. Here is the content of `bins`:\n",
        "\n",
        "~~~text\n",
        "[ 1  3  5  7  9 11 13 15 17 19 21 23 25 27 29 31 33 35 37 39 41 43 45 47 49 51 53 55 57 59]\n",
        "~~~\n",
        "\n",
        "Here is the summary statistics for the `TCort_dict` (see **Exercise 3A** above):\n",
        "\n",
        "~~~text\n",
        "----Summary Statistics for TCort ---------------------------\n",
        "                       count   mean  std_dev  min   max\n",
        "adenoma                  6.0   2.97     0.84  1.9   4.1\n",
        "bilateral hyperplasia   10.0   8.18     3.59  3.8  15.4\n",
        "carcinoma                5.0  19.72    17.21  9.2  53.8\n",
        "unknown                  6.0  14.02     9.22  2.6  30.0\n",
        "~~~\n",
        "\n",
        "You should note that the smallest value (`min`) is `1.9` and the largest value (`max`) is `53.8`. When generating the bin range, you need to make sure that it encompasses the minimum and maximum values. Otherwise, values outside of the bin range will not be visible in the plot. However, it is equally important not to make the bin range \"wider\" than needed, since this will make it harder to see differences in the data. In general, you will need to 'fiddle' with the values to get the best result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gN_fSXlxJtrC"
      },
      "outputs": [],
      "source": [
        "# Example 5B: PLot histograms\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from matplotlib.ticker import FuncFormatter\n",
        "\n",
        "# Set color\n",
        "color_1 = '#15365d' # Dark blue\n",
        "\n",
        "# Set bin width\n",
        "bin_width = 1.80\n",
        "\n",
        "# Define bins for TCort values\n",
        "bins = np.arange(1, 60, 2)\n",
        "\n",
        "# Create subplots\n",
        "fig, axs = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# Plot Type A\n",
        "counts, _ = np.histogram(TCort_dict['adenoma'], bins=bins)\n",
        "axs[0,0].bar(bins[:-1], counts, width=bin_width, color=color_1)\n",
        "axs[0,0].set_title(\"Adenoma\",fontsize=14)\n",
        "axs[0,0].tick_params(axis='x', labelsize=14)\n",
        "axs[0,0].tick_params(axis='y', labelsize=14)\n",
        "\n",
        "# Plot Type b\n",
        "counts, _ = np.histogram(TCort_dict['bilateral hyperplasia'], bins=bins)\n",
        "axs[0,1].bar(bins[:-1], counts, width=bin_width, color=color_1)\n",
        "axs[0,1].set_title(\"Bilateral Hyperplasia\", fontsize=14)\n",
        "axs[0,1].tick_params(axis='x', labelsize=14)\n",
        "axs[0,1].tick_params(axis='y', labelsize=14)\n",
        "\n",
        "# Plot Type c\n",
        "counts, _ = np.histogram(TCort_dict['carcinoma'], bins=bins)\n",
        "axs[1,0].bar(bins[:-1], counts, width=bin_width, color=color_1)\n",
        "axs[1,0].set_title(\"Carcinoma\", fontsize=14)\n",
        "axs[1,0].tick_params(axis='x', labelsize=14)\n",
        "axs[1,0].tick_params(axis='y', labelsize=14)\n",
        "\n",
        "# Plot Type u\n",
        "counts, _ = np.histogram(TCort_dict['unknown'], bins=bins)\n",
        "axs[1,1].bar(bins[:-1], counts, width=bin_width, color=color_1)\n",
        "axs[1,1].set_title(\"Unknown\", fontsize=14)\n",
        "axs[1,1].tick_params(axis='x', labelsize=14)\n",
        "axs[1,1].tick_params(axis='y', labelsize=14)\n",
        "\n",
        "# Plot text\n",
        "plt.text(-60, -0.2, 'Urinary Excretion of Tetrahydrocortisone (mg/24 hr)', fontsize=18)\n",
        "plt.text(-90.5, 0.8, 'Frequency', fontsize=18, rotation=90)\n",
        "\n",
        "# Adjust layout\n",
        "#plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftvWf6TlJtrD"
      },
      "source": [
        "If the code is correct, you should see the following set of bar plots.\n",
        "\n",
        "![____](https://biologicslab.co/BIO5853/images/module_03/lesson_03_4_image13.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lneOylDtJtrD"
      },
      "source": [
        "Recall that the primary reason that we wanted to generate histograms was to get a sense whether the data was \"normally distributed\". Compared to the histograms generated in Example 5A for the `fev1` data, these histograms are far from being normallly distributed. Part of the reason is the relatively small number of samples being plotted. For example, the plot for `Carcinoma` only has `5` values. Does that mean we can't used this data with ANOVA? Not necessarily, but we will need to proceed carefully!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Bj4daGvJtrD"
      },
      "source": [
        "### **Exercise 5: Plot Histograms**\n",
        "\n",
        "In the cell below, write the Python code to generate 4 histograms showing the urinary excretion rate (mg/24 hr) of Pregnanetriol, using the Python dictionary `NPreg_dict`.\n",
        "\n",
        "Here are the summary statistics for `NPreg_dict`:\n",
        "~~~text\n",
        "----Summary Statistics for NPreg ----------------------------\n",
        "                       count  mean  std_dev   min   max\n",
        "adenoma                  6.0  2.44     4.17  0.04  11.7\n",
        "bilateral hyperplasia   10.0  1.12     0.95  0.20   3.6\n",
        "carcinoma                5.0  5.50     2.27  2.50   7.9\n",
        "unknown                  6.0  1.20     1.72  0.10   5.0\n",
        "~~~\n",
        "\n",
        "You will need to make a few changes the code shown in Example 5B.\n",
        "\n",
        "1. Set the bin width to `0.45`\n",
        "2. Define the bin range as `bins = np.arange(0, 9, 0.5)`\n",
        "3. Here is the code you should use for plotting the text:\n",
        "\n",
        "~~~text\n",
        "# Plot text\n",
        "plt.text(-6.0, -0.6, 'Urinary Excretion of Pregnanetriol (mg/24 hr)', fontsize=18)\n",
        "plt.text(-13.5, 2.8, 'Frequency', fontsize=18, rotation=90)\n",
        "~~~"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-PmuHKUJtrD"
      },
      "outputs": [],
      "source": [
        "# Insert your code for Exercise 5 here\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcfPEZQ1JtrD"
      },
      "source": [
        "If the code is correct, you should see the following set of bar plots.\n",
        "\n",
        "![____](https://biologicslab.co/BIO5853/images/module_03/lesson_03_4_image10.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tA2ie7YSJtrD"
      },
      "source": [
        "Again, the histograms are not what you would call \"normally distributed\". However, like the TCort data, the sample size is pretty small."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nd5b8KI9JtrE"
      },
      "source": [
        "### Example 6A: One-Way ANOVA\n",
        "\n",
        "As you are aware by now, your textbook devotes a lot of pages to going step-by-step through a series of equations to explain how and why a particular statistical test works -- in this chapter ANOVA. For example, on pages 284-285, they show you how the test statistic _F_ is derived for the `fev1` data:\n",
        "\n",
        "$$ F = \\frac{s_B^2}{s_W^2} = \\frac{0.769}{0.254} = 3.03. $$\n",
        "\n",
        "What your textbook doesn't really show you is how to perform ANOVA using your computer.\n",
        "\n",
        "The code in the cell below performs a One-Way ANOVA analysis on the same `fev1` dataset used in the example shown on page 285.\n",
        "\n",
        "_Code Description:_\n",
        "\n",
        "The first step is to extract the numerical data store in each `key:value` pair in the dictionary `fev1_dict` into separate Numpy arrays. Here is the code that performs this extraction:\n",
        "~~~text\n",
        "# Extract the arrays from the dictionary\n",
        "arrays = [fev1_dict[key] for key in fev1_dict]\n",
        "~~~\n",
        "\n",
        "The code then uses the `f_oneway` function in the `scipy.stats` package to perform the ANOVA using this code chunk:\n",
        "\n",
        "~~~text\n",
        "# Perform one-way ANOVA\n",
        "f_statistic, p_value = f_oneway(*arrays)\n",
        "~~~\n",
        "\n",
        "The function `f_oneway()` returns two values, the `f-statistic` and the `p-value` which are then printed out."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "4-0vItQRJtrE"
      },
      "outputs": [],
      "source": [
        "# Example 6A: One-way anova\n",
        "\n",
        "import numpy as np\n",
        "from scipy.stats import f_oneway\n",
        "\n",
        "# Extract the arrays from the dictionary\n",
        "arrays = [fev1_dict[key] for key in fev1_dict]\n",
        "\n",
        "# Perform one-way ANOVA\n",
        "f_statistic, p_value = f_oneway(*arrays)\n",
        "\n",
        "# Print the results\n",
        "print(\"----ANOVA Results for fev1 data----------\")\n",
        "print(f\"F-statistic: {f_statistic:.2f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqLtL65nJtrE"
      },
      "source": [
        "If the code is correct, you should see the following output:\n",
        "\n",
        "~~~text\n",
        "----ANOVA Results for fev1 data----------\n",
        "F-statistic: 3.12\n",
        "P-value: 0.0520\n",
        "~~~"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRYjt7tqJtrE"
      },
      "source": [
        "The `F-statistic` of `3.12` is very close to the value of `3.03` shown on page 285:\n",
        "\n",
        ">Therefore, the test statistic is\n",
        "\n",
        "$$ F = \\frac{s_B^2}{s_W^2} = \\frac{0.769}{0.254} = 3.03. $$\n",
        "\n",
        "It's not uncommon for different statistical packages to generate slightly different values so we can ignore the slight difference between `3.12` and `3.03`. Your textbook doesn't give you an exact `_p_ -value` but states:\n",
        "\n",
        ">For an F distribution with _k_ − 1 = 3 − 1 = 2 and _n − k_ = 60 − 3 = 57 degrees of freedom,  0.05 < p < 0.10. Although we would reject the null hypothesis at the 0.10 level, we do not reject it at the 0.05 level. There may possibly be some difference among the mean $fev_1$ measurements for these three populations, but we are unable to state this with our specified level of significance.\n",
        "\n",
        "The _p_ -value returned by our function (`P-value: 0.0520`) is the same. Since it is slightly greater than `0.05` we can't reject it at the `0.05` confidence level.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsVch8tqJtrE"
      },
      "source": [
        "### Example 6B: One-Way ANOVA\n",
        "\n",
        "The code in the cell below shows how to perform a one-way anova on the TCort data stored in the `TCort_dict` dictionary. What we are doing is testing the null hypothesis:\n",
        "\n",
        "$$ H_0: \\mu_1 = \\mu_2 = \\mu_3 = \\mu_4,  $$\n",
        "\n",
        "Where = $\\mu_1$ is the mean urinary excretion of tetrahydrocortisone (mg/24 hr) in `adenoma` tumors, $\\mu_2$ is the mean urinary excretion of tetrahydrocortisone (mg/24 hr) from `bilateral hyperplasia` tumors, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vf2oa9IhJtrE"
      },
      "outputs": [],
      "source": [
        "# Example 6B: One-Way ANOVA\n",
        "\n",
        "import numpy as np\n",
        "from scipy.stats import f_oneway\n",
        "\n",
        "# Extract the arrays from the dictionary\n",
        "arrays = [TCort_dict[key] for key in TCort_dict]\n",
        "\n",
        "# Perform one-way ANOVA\n",
        "f_statistic, p_value = f_oneway(*arrays)\n",
        "\n",
        "# Print the results\n",
        "print(\"----ANOVA Results for TCort data----------\")\n",
        "print(f\"F-statistic: {f_statistic:.2f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j--eL_6VJtrE"
      },
      "source": [
        "If the code is correct, you should see the following output:\n",
        "\n",
        "~~~text\n",
        "----ANOVA Results for TCort data----------\n",
        "F-statistic: 3.23\n",
        "P-value: 0.0412\n",
        "~~~"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AG6-2sJUJtrE"
      },
      "source": [
        "Since the p-value (`0.0412`), we can reject the null hypothesis at the `0.05` level:\n",
        "\n",
        "$$ H_0: \\mu_1 = \\mu_2 = \\mu_3 = \\mu_4, $$\n",
        "\n",
        "So how should we interpret this result?\n",
        "\n",
        "_Rejecting_ the null hypothesis simply means that one (or more) of the tumor types execreted more tetrahydrocortisone that the other types. That's it! That's all an ANOVA analysis can tell you. In other words, \"one of these is not like the others\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkNkqly1JtrF"
      },
      "source": [
        "### **Exercise 6: One-Way ANOVA**\n",
        "\n",
        "In the cell below write the Python code to perform a one-way anova on the PregN data stored in the `PregN_dict` dictionary to test the null hypothesis:\n",
        "\n",
        "$$ H_0: \\mu_1 = \\mu_2 = \\mu_3 = \\mu_4,  $$\n",
        "\n",
        "Where = $\\mu_1$ is the mean urinary excretion of Pregnanetriol (mg/24 hr) in the four tumor types."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kf0A-hA9JtrF"
      },
      "outputs": [],
      "source": [
        "# Insert your code for Exercise 6 here\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udIWCcdHJtrF"
      },
      "source": [
        "If the code is correct, you should see the following output:\n",
        "\n",
        "~~~text\n",
        "----ANOVA Results for PregN data----------\n",
        "F-statistic: 3.54\n",
        "P-value: 0.0305\n",
        "~~~"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9H-vJM1AJtrF"
      },
      "source": [
        "Based on the ANOVA results, would your Reject, or Fail to Reject the null hypothesis?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekUJHoZyJtrF"
      },
      "source": [
        "![____](https://biologicslab.co/BIO5853/images/module_03/lesson_03_4_image14.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrFadQDvJtrF"
      },
      "source": [
        "![____](https://biologicslab.co/BIO5853/images/module_03/lesson_03_4_image15.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsecZHTwJtrF"
      },
      "source": [
        "## **Multiple Comparisons Procedures**  \n",
        "\n",
        "As we have seen, one-way analysis of variance may be used to test the null hypothesis that k  population means are identical,  \n",
        "\n",
        "$$ H_0: \\mu_1 = \\mu_2 = · · · = \\mu_k.  $$\n",
        "\n",
        "What happens, however, if we reject $H_0$? Although we can conclude that the population means are not all equal, we cannot be more specific than this. We do not know whether all the means are different from one another, or if only some of them are different. Once we reject the null hypothesis, therefore, we often want to conduct additional tests to find out where the differences lie. Many different techniques for  conducting multiple comparisons exist. They typically involve testing each pair of means individually. In the previous section, we mentioned that one possible approach is to perform a series of \u0010$\\binom{k}{2}$ two-sample t-tests. As noted, however, performing multiple tests increases the probability of committing a type I error. We can avoid this problem by being more  conservative in our individual comparisons; by reducing the individual α levels, we ensure that the  overall level of significance is kept at a predetermined level. The significance level for each of the individual comparisons depends on the number of tests being conducted. The greater the number of tests, the smaller it must be. To set the overall probability  of committing a type I error at 0.05, for example, we should use  \n",
        "\n",
        "$$ \\alpha^* = \\frac{0.05}{\\left(\\frac{k}{2}\\right)} $$ \u0011\n",
        "\n",
        "Pagano, Marcello; Gauvreau, Kimberlee; Mattie, Heather. Principles of Biostatistics (p. 286). CRC Press. Kindle Edition.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBt7eae9JtrF"
      },
      "source": [
        "#### **Install `statsmodel`**\n",
        "\n",
        "Just in case the Python packagage `statsmodel` is not in your current environment, run the next code cell to install it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "n_Y0SqmaJtrG",
        "outputId": "400d53bc-1162-40c4-96b7-2f01c35f58f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (0.14.3)\n",
            "Requirement already satisfied: numpy<3,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (1.26.4)\n",
            "Requirement already satisfied: scipy!=1.9.2,>=1.8 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (1.13.1)\n",
            "Requirement already satisfied: pandas!=2.1.0,>=1.4 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (2.2.2)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (0.5.6)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (24.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2024.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.6->statsmodels) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install statsmodels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fFKRlscJtrG"
      },
      "source": [
        "The output will either show that you are installing the package, or if the package is already installed:\n",
        "\n",
        "~~~text\n",
        "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (0.14.3)\n",
        "~~~"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mS4vs2AJJtrG"
      },
      "source": [
        "### **Bonferroni Correction**\n",
        "\n",
        "The **_Bonferroni correction_** is a statistical method used to address the problem of multiple comparisons. When you perform multiple hypothesis tests, the chance of making a Type I error (false positive) increases. The Bonferroni correction helps control this by adjusting the significance level for each individual test.\n",
        "\n",
        "#### **How It Works**\n",
        "* **Significance Level Adjustment:** If you have an overall significance level (alpha) of 0.05 and you are conducting ( n ) tests, the Bonferroni correction sets the significance level for each individual test to ( \\alpha / n ). For example, if you are conducting 5 tests, each test would have a significance level of ( 0.05 / 5 = 0.01 )12.\n",
        "* **P-Value Adjustment:** Alternatively, you can adjust the p-values instead of the significance level. Multiply each p-value by the number of tests. If the adjusted p-value is less than or equal to the original significance level, the result is considered statistically significant12.\n",
        "\n",
        "#### **Example**\n",
        "Suppose you are testing 10 hypotheses with an overall alpha of 0.05. Using the Bonferroni correction, each test would have an adjusted alpha of ( 0.05 / 10 = 0.005 ). This means a result would need to have a p-value less than 0.005 to be considered significant.\n",
        "\n",
        "#### **Applications**\n",
        "The Bonferroni correction is commonly used in:\n",
        "\n",
        "* **Clinical Trials:** To control for multiple endpoints.\n",
        "* **Genetic Studies:** When testing associations between many genetic markers and a trait.\n",
        "* **Psychological Research:** When comparing multiple groups or conditions.\n",
        "\n",
        "Run the next code cell to see how the Bonferroni correction changes (\"corrects\") _p_ -values when you run multiple comparison procedures on the same data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dN7ogjGoJtrG"
      },
      "outputs": [],
      "source": [
        "# Example of Bonferroni correction\n",
        "\n",
        "import numpy as np\n",
        "from statsmodels.stats.multitest import multipletests\n",
        "\n",
        "# Example p-values from multiple hypothesis tests\n",
        "p_values = np.array([0.01, 0.04, 0.03, 0.002, 0.05])\n",
        "\n",
        "# Apply Bonferroni correction\n",
        "alpha = 0.05  # significance level\n",
        "corrected_p_values = multipletests(p_values, alpha=alpha, method='bonferroni')\n",
        "\n",
        "# Extract the adjusted p-values and the reject decision\n",
        "adjusted_p_values = corrected_p_values[1]\n",
        "reject_decision = corrected_p_values[0]\n",
        "\n",
        "print(\"----Examples of Bonferroni Corrections----------\")\n",
        "print(\"Original p-values:\", p_values)\n",
        "print(\"Adjusted p-values:\", adjusted_p_values)\n",
        "print(\"Reject null hypothesis:\", reject_decision)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyvBLHZPJtrG"
      },
      "source": [
        "If the code if correct, you should see the following output:\n",
        "~~~text\n",
        "----Examples of Bonferroni Corrections----------\n",
        "Original p-values: [0.01  0.04  0.03  0.002 0.05 ]\n",
        "Adjusted p-values: [0.05 0.2  0.15 0.01 0.25]\n",
        "Reject null hypothesis: [ True False False  True False]\n",
        "~~~"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dShas17xJtrG"
      },
      "source": [
        "![____](https://biologicslab.co/BIO5853/images/module_03/lesson_03_4_image16.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMlPX3GUJtrG"
      },
      "source": [
        "## **Further Applications**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Jm2fhcNJtrG"
      },
      "source": [
        "You were shown in Example 4A, Example 4B, and **Exercise 4**, how to use your computer to perform an ANOVA analysis of numerical data stored in a Python dictionary. While these examples are useful, much more useful is to see how to perform ANOVA on data that is stored in DataFrame, which is the most common method of storing data in biological and/or medical datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CK0bwXAJtrH"
      },
      "source": [
        "### **The `Genotype` dataset**\n",
        "\n",
        "For the last part of this lesson, we will be using the data in the `genotype` dataset that you were asked to download and create a new DataFrame called `genoDF` in **Exercise 1B**.\n",
        "\n",
        "The genotype dataset in the MASS package is a well-known dataset used in statistical analysis and educational purposes. It contains data on the weights of mice from different genotypes. Here’s a brief overview of what it includes and its significance:\n",
        "\n",
        "#### **Overview of the genotype Dataset**\n",
        "\n",
        "* **Source:** The dataset is part of the MASS package in R, which is a collection of functions and datasets to support the book _Modern Applied Statistics with S_ by W.N. Venables and B.D. Ripley.\n",
        "* **Variables:**\n",
        "- **Litter:** Identifier for the litter (group of mice born at the same time).\n",
        "- **Mother:** Identifier for the mother of the litter.\n",
        "- **Wt:** The weight gain of the rat litter after 28 days.\n",
        "- **Sex:** Sex of the mice (Male or Female).\n",
        "- **Genotype:** Genotype of the mice (e.g., AA, AB, BB).\n",
        "\n",
        "#### **Significance**\n",
        "\n",
        "The genotype dataset is often used to demonstrate various statistical techniques, such as ANOVA (Analysis of Variance) to compare the weights of mice across different genotypes.\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "scrolled": true,
        "id": "JTZo1Ms4JtrH"
      },
      "source": [
        "# Example 1: Read datafile\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Read the datafile\n",
        "genoDF = pd.read_csv(\n",
        "    \"https://biologicslab.co/BIO5853/data/genotype.csv\",\n",
        "#    index_col=0,\n",
        "    sep=',',\n",
        "    na_values=['NA','?'])\n",
        "\n",
        "# Set max rows and max columns\n",
        "pd.set_option('display.max_rows', 6)\n",
        "pd.set_option('display.max_columns', 4)\n",
        "\n",
        "# Display DataFrame\n",
        "display(genoDF)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14kWS1umJtrH"
      },
      "source": [
        "### Example 7: Perform ANOVA on Data in a DataFrame\n",
        "\n",
        "The cell below shows the Python code to perform an ANOVA on the `genotype` data in the DataFrame `genoDF`. In this example, we are using the variable `Mother` as the **_independent variable_** and weight gain of the litter `Wt` as the dependent variable. The null hypothesis is that the average weight gain of the 4 litters after 28 days did _not_ vary significantly depending upon the `Mother`.\n",
        "\n",
        "_Code Description:_\n",
        "\n",
        "Here is the code chunk that performs the ANOVA:\n",
        "\n",
        "`model = ols('Wt ~ Mother', data=genoDF).fit()`\n",
        "\n",
        "This line of code performs an Ordinary Least Squares (OLS) regression using the statsmodels library in Python. Here’s a breakdown of what each part does:\n",
        "\n",
        "1. `ols('Wt ~ Mother', data=genoDF)`:\n",
        "- - `ols:` This function from statsmodels.formula.api specifies an OLS regression model.\n",
        "- - `'Wt ~ Mother':` This is the formula for the regression model. It indicates that Wt (weight) is the dependent variable and Mother is the independent variable. The tilde (~) separates the dependent variable from the independent variable(s).\n",
        "-- `data=genoDF:` This specifies that the data for the regression model is in the DataFrame genoDF.\n",
        "2. `.fit():`\n",
        "This method fits the OLS regression model to the data. It estimates the coefficients of the regression model.\n",
        "\n",
        "The next line of code:\n",
        "\n",
        "`anova_table = sm.stats.anova_lm(model, typ=2)`\n",
        "\n",
        "performs the actual Analysis of Variance (ANOVA) on the fitted linear model `model` using the statsmodels library.\n",
        "\n",
        "Here’s a detailed breakdown:\n",
        "\n",
        "1. `sm.stats.anova_lm(model, typ=2)`:\n",
        "- - `sm.stats.anova_lm:` This function from the statsmodels library generates an ANOVA table for one or more fitted linear models.\n",
        "- - `model:` This is the fitted linear model object created earlier using the ols function and the .fit() method.\n",
        "- - `typ=2:` This specifies the type of ANOVA to perform. Type II ANOVA is used when you want to test each main effect after accounting for all other main effects, but without considering interactions12.\n",
        "2. `anova_table:`\n",
        "- This variable stores the resulting ANOVA table, which includes important statistics such as:\n",
        "- * **Sum of Squares (sum_sq):** Measures the variability explained by each factor.\n",
        "- * **Degrees of Freedom (df):** The number of independent values or quantities which can be assigned to a statistical distribution.\n",
        "- * **F-Statistic (F):** The ratio of the variance explained by the model to the variance within the groups.\n",
        "- * **P-Value (PR(>F)):** Indicates the probability that the observed data would occur if the null hypothesis were true.\n",
        "\n",
        "At the bottom of the cell is several lines of code used to create a Python list called `grouped_data` which is used for **_Bartlett's test_**.\n",
        "Bartlett’s test is a statistical test used to determine whether multiple samples have equal variances. This is important because many statistical tests, like ANOVA (Analysis of Variance), assume that the variances across groups are equal. Bartlett’s test helps verify this assumption.\n",
        "\n",
        "Here’s a brief overview of how Bartlett’s test works:\n",
        "\n",
        "1. **Hypotheses:**\n",
        "- **Null Hypothesis ($H_0$):** All groups have equal variances.\n",
        "- **Alternative Hypothesis ($H_A$):** At least one group has a different variance.\n",
        "2. **Test Statistic:**\n",
        "- The test statistic for Bartlett’s test follows a chi-square distribution. It is calculated based on the variances of the groups and the number of observations in each group.\n",
        "3. **Sensitivity:**\n",
        "Bartlett’s test is sensitive to departures from normality. If the data is not normally distributed, the test may incorrectly indicate unequal variances. In such cases, alternatives like Levene’s test or the Brown-Forsythe test, which are less sensitive to non-normality, might be more appropriate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HrfQdlzrJtrH"
      },
      "outputs": [],
      "source": [
        "# Example 7: Perform ANOVA on DataFrame\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "\n",
        "# Define variables\n",
        "independent_var = 'Mother'\n",
        "dependent_var = 'Wt'\n",
        "\n",
        "# Print header\n",
        "print(\"----ANOVA Results for Genotype data----------\")\n",
        "\n",
        "# Summary statistics\n",
        "summary = genoDF.groupby(independent_var)[dependent_var].agg(['mean', 'std', 'count'])\n",
        "print(summary)\n",
        "\n",
        "# ANOVA\n",
        "model = ols(f'({dependent_var} ~ {independent_var})', data=genoDF).fit()\n",
        "anova_table = sm.stats.anova_lm(model, typ=2)\n",
        "print(anova_table)\n",
        "\n",
        "# Generate grouped data for Bartlett's test\n",
        "# Initialize an empty list to store the grouped data\n",
        "grouped_data = []\n",
        "\n",
        "# Get the unique groups from the independent variable\n",
        "unique_groups = genoDF[independent_var].unique()\n",
        "\n",
        "# Loop through each unique group\n",
        "for group in unique_groups:\n",
        "    # Filter the DataFrame for the current group\n",
        "    group_data = genoDF[dependent_var][genoDF[independent_var] == group]\n",
        "\n",
        "    # Append the filtered data to the grouped_data list\n",
        "    grouped_data.append(group_data)\n",
        "\n",
        "# Check for missing values\n",
        "if genoDF['Wt'].isnull().any():\n",
        "    print(f\"Warning: Missing values detected in {dependent_var} column. Please handle them before proceeding.\")\n",
        "else:\n",
        "    # Bartlett's test for equal variances\n",
        "    bartlett_test = stats.bartlett(*grouped_data)\n",
        "    print(f\"Bartlett's test: chi2 = {bartlett_test.statistic:.4f}, p-value = {bartlett_test.pvalue:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVJZnxn2JtrH"
      },
      "source": [
        "If the code is correct, you should see the following output:\n",
        "\n",
        "~~~text\n",
        "----ANOVA Results for Genotype data  -------------\n",
        "           mean       std  count\n",
        "Mother                          \n",
        "A       55.4000  9.889186     16\n",
        "B       58.7000  7.242078     14\n",
        "I       53.3625  6.452790     16\n",
        "J       48.6800  6.297301     15\n",
        "               sum_sq    df         F    PR(>F)\n",
        "Mother     771.605385   3.0  4.404509  0.007433\n",
        "Residual  3328.521500  57.0       NaN       NaN\n",
        "Bartlett's test: chi2 = 4.0342, p-value = 0.2578\n",
        "~~~"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSi730LPJtrH"
      },
      "source": [
        "As usual, we look to see if any _p_ -values are less than `0.05`. For the ANOVA test, the _p_ -value for `Mother` is `0.007433` which is definitely smaller than our `0.05` level. This means there is a **_statistically significant_** interaction between our independent variable (`Mother`) and the dependent variable (`Wt`). In other words we can **_reject_** the null hypothesis ($H_0$) that average weight gain for each litter did _not_ depend upon the mother ('A', 'B', 'I', and 'J'). Therefore we have to accept the alternative hypothesis ($H_A$) that weight was different for different rat mothers.\n",
        "\n",
        "You should also note that the `Bartlett's test: p-value = 0.2578` is **_greater_** that `0.05`. This means we can't reject the null hypothesis that the `genome` data were not normally distributed. In other words, there is no evidence that the data was significantly skewed so application of ANOVA is appropiate for this dataset.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlZlGG-8JtrI"
      },
      "source": [
        "### **Exercise 7: Perform ANOVA on Data in a DataFrame**\n",
        "\n",
        "In the cell below, write the Python code to perform an ANOVA on the `genotype` data in the DataFrame `genoDF` with the independent variable `Litter` and the dependent variable `Wt`.\n",
        "\n",
        "_Hint:_ You only need to change the name for `independent_var`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "AVoqqMoEJtrI"
      },
      "outputs": [],
      "source": [
        "# Insert your code for Exercise 7 here\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwkBxs1NJtrI"
      },
      "source": [
        "If your code is correct, you should see the following output:\n",
        "\n",
        "~~~text\n",
        "----ANOVA Results for Genotype data----------\n",
        "             mean        std  count\n",
        "Litter                             \n",
        "A       55.111765   8.634370     17\n",
        "B       54.666667   7.133689     15\n",
        "I       52.907143  11.273349     14\n",
        "J       52.973333   5.870808     15\n",
        "               sum_sq    df        F    PR(>F)\n",
        "Litter      60.157286   3.0  0.28292  0.837515\n",
        "Residual  4039.969599  57.0      NaN       NaN\n",
        "Bartlett's test: chi2 = 6.1503, p-value = 0.1045\n",
        "~~~"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wiSn4A3JtrI"
      },
      "source": [
        "Now we don't see any _p_ -values that are less than `0.05`. For the ANOVA test, the _p_ -value for `Litter` is `0.837515` which is definitely larger than our `0.05` level. This means there is no **_statistically significant_** interaction between our independent variable (`Litter`) and the dependent variable (`Wt`). A non-significant ANOVA result suggests that any observed differences in weight gain among the different litter genotypes are likely due to random variation rather than a true effect of the litter genotype.\n",
        "\n",
        "Again. Bartlett's test returned a _p_ -value (`0.`1045`) that is greated than the `0.05` level suggesting that the data was approximately normally distributed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyZaM2KXJtrI"
      },
      "source": [
        "## **Lesson Turn-in**\n",
        "\n",
        "When you have completed and run all of the code cells, create a PDF of your notebook and upload the **_PDF_** to your Lesson_03_4 assignment in Canvas for grading.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}