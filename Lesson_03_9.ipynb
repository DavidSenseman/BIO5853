{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DavidSenseman/BIO5853/blob/main/Lesson_03_9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GF1Zvk3zuAzj"
      },
      "source": [
        "---------------------------\n",
        "\n",
        "**COPYRIGHT NOTICE:** This Jupyterlab/Colab notebook is a companion supplement to the textbook _Principles of Biostatistics_ by M. Pagano. K. Marcello and H. Mattie (3rd ed) published in 2022 by CRC Press. It is designed to be used in conjunction with -- not as a standalone substitute for – this textbook.  \n",
        "\n",
        "This notebook is licensed under the Apache License, Version 2.0 (the \"License\"); You may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
        ">http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.\n",
        "\n",
        "------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWhzAfdYuAzk"
      },
      "source": [
        "# **BIO 5853: Biostatistics**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_S-MMUU_uAzk"
      },
      "source": [
        "##### **Module 3: Inference**\n",
        "\n",
        "* Instructor: [David Senseman](mailto:David.Senseman@utsa.edu), [Department of Integrative Biology](https://sciences.utsa.edu/integrative-biology/), [UTSA](https://www.utsa.edu/)\n",
        "\n",
        "\n",
        "### Module 3 Material\n",
        "\n",
        "* Part 3.1: Confidence Intervals\n",
        "* Part 3.2: Hypothesis Testing\n",
        "* Part 3.3: Comparison of Two Means\n",
        "* Part 3.4: Analysis of Variance (ANOVA)\n",
        "* Part 3.5: Nonparametric Methods\n",
        "* Part 3.6: Inference on Proportions\n",
        "* Part 3.7: Contingency Tables\n",
        "* Part 3.8: Correlation\n",
        "* **Part 3.9: Simple Linear Regression**\n",
        "* Part 3.10: Multiple Linear Regression\n",
        "* Part 3.11: Logistic Regression\n",
        "* Part 3.12: Survival Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKQylnEiLDUM"
      },
      "source": [
        "## Google CoLab Instructions\n",
        "\n",
        "The following code ensures that Google CoLab is running the correct version of TensorFlow.\n",
        "  Running the following code will map your GDrive to ```/content/drive```."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# YOU MUST RUN THIS CODE CELL FIRST\n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    from google.colab import auth\n",
        "    auth.authenticate_user()\n",
        "    COLAB = True\n",
        "    print(\"Note: using Google CoLab\")\n",
        "    import requests\n",
        "    gcloud_token = !gcloud auth print-access-token\n",
        "    gcloud_tokeninfo = requests.get('https://www.googleapis.com/oauth2/v3/tokeninfo?access_token=' + gcloud_token[0]).json()\n",
        "    print(gcloud_tokeninfo['email'])\n",
        "except:\n",
        "    print(\"Note: not using Google CoLab\")\n",
        "    COLAB = False"
      ],
      "metadata": {
        "id": "uSeBRhXpZkHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Li15Da3vuAzm"
      },
      "source": [
        "# **Part 3.9: Simple Linear Regression**\n",
        "\n",
        "Simple linear regression is a statistical method that models the relationship between two variables by fitting a linear equation to observed data. One variable is the independent (or predictor) variable, and the other is the dependent (or response) variable. The equation of the line is typically written as:\n",
        "\n",
        "$$ y = \\beta_0 + \\beta_1 x + \\epsilon $$\n",
        "\n",
        "where:\n",
        "\n",
        "* *$y$* is the dependent variable.\n",
        "* *$x$* is the independent variable.\n",
        "* *$\\beta_0$* is the y-intercept.\n",
        "* *$\\beta_1$* is the slope of the line.\n",
        "* *$\\epsilon_1$* is the error term.\n",
        "\n",
        "#### **Importance for Biostatistics**\n",
        "\n",
        "* **Predictive Modeling:** Helps predict outcomes (e.g., predicting disease risk based on an exposure level).\n",
        "* **Understanding Relationships:** Quantifies the relationship between variables (e.g., the relationship between smoking and lung function).\n",
        "* **Public Health:** Aids in evaluating the impact of interventions (e.g., the effect of a new drug on blood pressure).\n",
        "* **Research:** Fundamental in designing and interpreting experiments and observational studies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TH5na1-uAzm"
      },
      "source": [
        "### **Introduction**\n",
        "\n",
        "Like correlation analysis, **_simple linear regression_** is a technique that is used to explore the nature of the relationship between two continuous random variables. The primary difference between these two analytical methods is that regression enables us to investigate the change in one variable, called the **_response_** or **_outcome_**, which corresponds to a given change in the other, the **_explanatory variable_**. Correlation analysis makes no such distinction; the two variables involved are treated symmetrically. The ultimate objective of regression analysis is to predict or estimate the value of the response that is associated with a fixed value of the explanatory variable.  \n",
        "\n",
        ">Pagano, Marcello; Gauvreau, Kimberlee; Mattie, Heather. Principles of Biostatistics (p. 399). CRC Press. Kindle Edition."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zqEnNPkuAzn"
      },
      "source": [
        "## **Datasets for this Lesson**\n",
        "\n",
        "In this lesson we will be using 3 datasets that we need to read from the course file server."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5b5r6ao0uAzn"
      },
      "source": [
        "### Example 1: Read Datafile\n",
        "\n",
        "We will be using a datafile called `lowbwt_ga.csv` stored on the course HTTPS server. As the file is read, the data is stored in a DataFrame called `headDF`.\n",
        "\n",
        "_Data Description:_\n",
        "\n",
        "This file contains head circumference measurements in cm for a population of low birth weight infants--defined as those weighing less than 1500 gms--born in two teaching hospitals in Boston, Massachusetts. The mean head circumference for the infants in this population is\n",
        "\n",
        "$$ \\mu_y = 27.0 cm $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "CVlabeawuAzn"
      },
      "outputs": [],
      "source": [
        "# Example 1: Read datafile\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Read datafile and create DataFrame\n",
        "headDF = pd.read_csv(\n",
        "    \"https://biologicslab.co/BIO5853/data/lowbwt_ga.csv\",\n",
        "    index_col=0,\n",
        "    sep=',',\n",
        "    na_values=['NA','?'])\n",
        "\n",
        "# Set max rows and max columns\n",
        "pd.set_option('display.max_rows', 6)\n",
        "pd.set_option('display.max_columns', 8)\n",
        "\n",
        "# Display DataFrame\n",
        "display(headDF)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkYkPRy2uAzn"
      },
      "source": [
        "If the code is correct, you should see the following output:\n",
        "\n",
        "![____](https://biologicslab.co/BIO5853/images/module_03/lesson_03_9_image33.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsLK6Hn6uAzo"
      },
      "source": [
        "The column `count` contains the number of times the same values for `headcirc` and `gestage` were recorded. The `count` value will be used below to change the marker size in scatterplots of this dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8P89pgBduAzo"
      },
      "source": [
        "### **Exercise 1A: Read Datafile**\n",
        "\n",
        "In the cell below, use the Pandas function `pd.read_csv(filename)` to read a data file called `saltBP.txt` stored on the course HTTPS server. As the file is read, store it in a new Pandas DataFrame called `saltDF`.\n",
        "\n",
        "_Code Notes:_\n",
        "\n",
        "In order to read this file correctly, you must make two code changes:\n",
        "\n",
        "1. Comment out the line `index_col=0,`\n",
        "2. Change the argument `sep` from a comma `','` to a space `' ' `.\n",
        "\n",
        "_Data Description:_\n",
        "\n",
        "In this data set, BP shows the observed systolic blood pressure, salt shows the amount of sodium chloride intake per day, and saltLevel is a binary variable indicating whether sodium chloride intake per day is less than 6 grams (saltLevel = 0) or above 6 grams (saltLevel = 1).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "N6kiFp-guAzo"
      },
      "outputs": [],
      "source": [
        "# Insert your code for Exercise 1A here\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIelUcBNuAzo"
      },
      "source": [
        "If your code is correct, you should see the following output:\n",
        "\n",
        "![____](https://biologicslab.co/BIO5853/images/module_03/lesson_03_9_image34.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teyWGB2buAzo"
      },
      "source": [
        "**WARNING:** If your output doesn't look exactly like this, it probably means that you didn't change the `sep` argument. Don't proceed until you have correctly read this file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHMelJrQuAzo"
      },
      "source": [
        "### **Exercise 1B: Read Datafile**\n",
        "\n",
        "In the cell below, use the Pandas function `pd.read_csv(filename)` to read a data file called `gdp_birth_2015.csv` stored on the course HTTPS server. As the file is read, store it in a new Pandas DataFrame called `gdpDF`.\n",
        "\n",
        "_Code Notes:_\n",
        "\n",
        "In order to read this file correctly, you must reverse the changes that you made in **Exercise 1A**\n",
        "\n",
        "1. Uncomment the line `index_col=0,`\n",
        "2. Change the argument `sep` from a space `' ' ` back to a comma `','`\n",
        "\n",
        "_Data Description:_\n",
        "\n",
        "This file contains birth weight data from 241 countries from Aruba to Zimbabwe along with the country's gross domestric product (gdp).  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "5D6nw08euAzo"
      },
      "outputs": [],
      "source": [
        "# Insert your code for Exercise 1B here\n",
        "\n",
        "import pandas as pd\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MAZp6QquAzp"
      },
      "source": [
        "If your code is correct, you should see the following output:\n",
        "\n",
        "![____](https://biologicslab.co/BIO5853/images/module_03/lesson_03_9_image02.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ns9N-51HuAzp"
      },
      "source": [
        "## **The Model**\n",
        "\n",
        "We are now ready to take what we know about the probability distributions of head circumference $Y$ for individual values of gestational age $X$ and use this information to model $Y$ across the entire range of $X$ values.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPUStSt5uAzp"
      },
      "source": [
        "### **Population Regression Line**\n",
        "\n",
        "As noted in the preceding section, mean head circumference increases as gestational age increases. Based on the means plotted in Figure 17.3, the relationship is linear. One way to quantify this relationship is to fit a model of the form\n",
        "\n",
        "$$ \\mu_{y|x} = \\beta_0 + \\beta_1 x, $$\n",
        "\n",
        "where $( \\mu_{y|x} $) is the mean head circumference of low birth weight infants whose gestational age is $( x $) weeks. This model – known as the population regression line – is the equation of a straight line. The parameters $( \\beta_0 $) and $( \\beta_1 $) are constants called the coefficients of the equation; $( \\beta_0 $) is the y-intercept of the line and $( \\beta_1 $) is its slope. The y-intercept is the mean value of the response $( y $) when $( x $) is equal to 0, or $( \\mu_{y|0} $). The slope is the change in the mean value of $( y $) that corresponds to a one-unit increase in $( x $). If $( \\beta_1 $) is positive, $( \\mu_{y|x} $) increases in magnitude as $( x $) increases. If $( \\beta_1 $) is negative, $( \\mu_{y|x} $) decreases as $( x $) increases.\n",
        "\n",
        "Even if the relationship between mean head circumference and gestational age is a perfect straight line as implied by this model, the relationship between individual values of head circumference and age is not. As previously noted, the distribution of head circumference measurements for all low birth weight infants of a particular gestational age $x$ is approximately normal with with $\\mu_{y | x}$ and the standard deviation $\\sigma_{y | x}$. The scatter around the mean is a result of the natural variation among children. To accomodate this scatter, we actually fit a model of the form\n",
        "\n",
        "$$ y = \\beta_0 + \\beta_1 x + \\epsilon $$\n",
        "\n",
        "where $\\epsilon$ is the distance a particular outcome $y$ lies from the population regression line.\n",
        "\n",
        "$$ \\mu_{y | x} = \\beta_0 + \\beta_1 x $$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "scrolled": true,
        "id": "uIOdS4_auAzp"
      },
      "source": [
        "![____](https://biologicslab.co/BIO5853/images/module_03/lesson_03_9_image03.png)\n",
        "\n",
        "**FIGURE 17.3**  Population regression line of mean head circumference versus gestational age for low birth weight infants, $\\mu_{y|x}$ = 2.3 + 0.83x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvhZd88muAzp"
      },
      "source": [
        "### Example 2: Population Regression Line\n",
        "\n",
        "The code in the cell below recreate **Figure 17.3** from your textbook.\n",
        "\n",
        "_Code Description:_\n",
        "\n",
        "To generate this figure, you need to manually enter the following values:\n",
        "\n",
        "1. y-intercept ($\\beta_0$)\n",
        "2. slope ($\\beta_1$)\n",
        "3. minimum $x$ value\n",
        "4. maximum $x$ value\n",
        "\n",
        "Using these values, the code generates $x$ and $y$ values for the plot using the following code chunk:\n",
        "\n",
        "~~~text\n",
        "# Generate x, y\n",
        "x = np.array([min_x, mid_x, max_x])\n",
        "y = beta_0 + beta_1 * x\n",
        "~~~"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9idGoaauAzp"
      },
      "outputs": [],
      "source": [
        "# Example 2: Population regression line\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "\n",
        "# Enter beta_0 and beta_1\n",
        "beta_0 = 2.3\n",
        "beta_1 = 0.83\n",
        "\n",
        "# Enter min x and max x values\n",
        "min_x = 26\n",
        "max_x = 32\n",
        "\n",
        "# Compute the middle value\n",
        "mid_x = (min_x + max_x) / 2\n",
        "\n",
        "# Generate x, y\n",
        "x = np.array([min_x, mid_x, max_x])\n",
        "y = beta_0 + beta_1 * x\n",
        "\n",
        "# Create plotting environment\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "# Assign color value\n",
        "color_1 = '#15466d' # Dark blue\n",
        "\n",
        "# Plot xy line\n",
        "ax.plot(x,y,\n",
        "        linewidth=2,\n",
        "        alpha = 1,\n",
        "        color=color_1)\n",
        "\n",
        "# Plot xy scatter\n",
        "ax.scatter(x, y, marker=\"o\",\n",
        "           s=40,  # marker size\n",
        "           linestyle='None',\n",
        "           facecolor='white',\n",
        "           alpha = 1,\n",
        "           edgecolors=color_1)\n",
        "\n",
        "# Set x and y limits\n",
        "ax.set(xlim=(23,35))\n",
        "ax.set(ylim=(21.5,31.5))\n",
        "\n",
        "# Set the x and y labels\n",
        "ax.set_xlabel('Gestational age (weeks)', fontsize=12)\n",
        "ax.set_ylabel('Head circumference (cm)', fontsize=12)\n",
        "\n",
        "# Show plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCipnLoWuAzp"
      },
      "source": [
        "If the code is correct, you should see the following plot:\n",
        "\n",
        "![____](https://biologicslab.co/BIO5853/images/module_03/lesson_03_9_image35.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adv2QwtCuAzq"
      },
      "source": [
        "### **Exercise 2: Population Regression Line**\n",
        "\n",
        "In the cell below plot the population regression line for the salt/blood pressure dataset stored in the DataFrame `saltDF`.  \n",
        "\n",
        "_Code Description:_\n",
        "\n",
        "To generate this figure, you will need to manually enter the following values:\n",
        "\n",
        "1. y-intercept ($\\beta_0$) = `128.61`\n",
        "2. slope ($\\beta_1$) = `1.1969`\n",
        "3. minimum $x$ value = `1.13`\n",
        "4. maximum $x$ value = `12.57`\n",
        "\n",
        "In addition you will need to change the x- and y-limits:\n",
        "~~~text\n",
        "# Set x and y limits\n",
        "ax.set(xlim=(-0.5,14))\n",
        "ax.set(ylim=(125,145))\n",
        "~~~\n",
        "\n",
        "Label the x-axis \"Salt\" and the y-axis \"BP\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nY30sIZfuAzq"
      },
      "outputs": [],
      "source": [
        "# Insert your code for Exercise 2 here\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfU6pzYyuAzq"
      },
      "source": [
        "If your code is correct, you should see the following plot:\n",
        "\n",
        "![____](https://biologicslab.co/BIO5853/images/module_03/lesson_03_9_image36.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-ERNTVLuAzq"
      },
      "source": [
        "#### **Assumptions for fitting a regression line:**\n",
        "\n",
        "\n",
        "In a simple linear regression, the coefficients of the population regression line are estimated using a random sample of observations ($x_i, y_i$). Before we attempt to fit such as line, we must make a few assumptions:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIWKnKDyuAzq"
      },
      "source": [
        "\n",
        "\n",
        "1. For a specified value of $( x $), which is considered to have been measured without error, the distribution of the $( y $) values is normal with mean $( \\mu_{y|x} $) and standard deviation $( \\sigma_{y|x} $). This concept is illustrated in **Figure 17.4**.\n",
        "\n",
        "2. The relationship between $( \\mu_{y|x} $) and $( x $) is described by the straight line\n",
        "   \n",
        "$$   \\mu_{y|x} = \\beta_0 + \\beta_1 x. $$\n",
        "\n",
        "3. For any specified value of $( x $), $( \\sigma_{y|x} $) – the standard deviation of the outcomes $( y $) – does not change. This assumption of constant variability across all values of $( x $) is known as **_homoscedasticity_**. It is analogous to the assumption of equal variances in the two-sample $( t $) test or the one-way analysis of variance.\n",
        "\n",
        "4. The outcomes $( y $) are independent.\n",
        "\n",
        "\n",
        "\n",
        "![____](https://biologicslab.co/BIO5853/images/module_03/lesson_03_9_image05.png)\n",
        "\n",
        "**FIGURE 17.4** Normality of the outcomes $Y$ for given values of $X$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzXRiPU3uAzq"
      },
      "source": [
        "## **Method of Least Squares**\n",
        "\n",
        "The method of least squares is a fundamental statistical technique used to find the best-fitting line or curve for a set of data points by minimizing the sum of the squares of the differences between the observed values and the values predicted by the model. Essentially, it works to reduce the discrepancies between observed data and the predictions made by the model.\n",
        "\n",
        "#### **How It Works:**\n",
        "* **Model Specification:** Start with a linear model: $y = \\beta_0 + \\beta_1 x + \\epsilon$\n",
        "* **Error Calculation:** Compute the error term $\\epsilon$ for each data point, which is the difference between the observed $y$ and the predicted $\\hat{y}$\n",
        "* **Minimization:** Find the values of $\\beta_0$ and $\\beta_1$ that minimize the sum of $\\epsilon^2$, the squared differences between observed and predicted values.\n",
        "\n",
        "#### **Importance in Biostatistics:**\n",
        "\n",
        "1. **Predictive Analysis:** Helps in predicting outcomes based on predictor variables. For example, predicting disease incidence based on exposure levels.\n",
        "2. **Understanding Relationships:** Quantifies the strength and nature of relationships between biological variables, such as the effect of a drug on blood pressure.\n",
        "3. **Statistical Inference:** Provides a framework for hypothesis testing and confidence intervals, aiding in the interpretation of experimental results.\n",
        "4. **Design of Experiments:** Informs the design and analysis of clinical trials, observational studies, and laboratory experiments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9R0pUkQ2uAzq"
      },
      "source": [
        "Here is a two-way scatterplot of the head circumferences versus gestational age for our sample of 100 low weight infants. As you can see, the marker size varies. Changing the marker size is one technique that is used to reveal x,y locations in which there are two (or more) datapoints plotted at the same coordinate. For example the largest marker at gestational age 29 weeks with a head circumference of 27 cm represents 9 unique infants.  \n",
        "\n",
        "![____](https://biologicslab.co/BIO5853/images/module_03/lesson_03_9_image10.png)\n",
        "\n",
        "**FIGURE 17.5**  Head circumference versus gestational age for a sample of 100 low birth weight infants  coefficients of a population regression line using a single sample of measurements."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXdcDzYbuAzq"
      },
      "source": [
        "### Example 3: Two-Way Scatter Plot\n",
        "\n",
        "The code in the cell below shows how to recreate **Figure 17.5** using Python.\n",
        "\n",
        "_Code Decription:_\n",
        "\n",
        "This code chunk that extracts the `x`, `y` and `count` values as numpy arrays:\n",
        "\n",
        "~~~text\n",
        "# Extract x- y-values and counts\n",
        "x = np.array(headDF['gestage'])\n",
        "y = np.array(headDF['headcirc'])\n",
        "counts = np.array(headDF['count'])\n",
        "~~~\n",
        "\n",
        "This dataset is rather unusual in having a separate column (`count`) containing the number of times a particular gestational age/head circumference measurement was repeated.\n",
        "\n",
        "Here is the line of code that uses the `count` value to increase the size of the marker:\n",
        "\n",
        "~~~text\n",
        "scatter = ax.scatter(x,y, s=counts*20, facecolor='white', edgecolor=color_1)\n",
        "~~~\n",
        "\n",
        "The argument `s` species the marker size. The default marker size = `20` when `count` = `1` for a particular x,y pair. The marker size is increased by a factor of `20` for each additional count."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bBLycr5EuAzr"
      },
      "outputs": [],
      "source": [
        "# Example 3: Two-Way Scatter Plot\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Extract x- y-values and counts\n",
        "x = np.array(headDF['gestage'])\n",
        "y = np.array(headDF['headcirc'])\n",
        "counts = np.array(headDF['count'])\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame({'x': x, 'y': y})\n",
        "\n",
        "# Create plotting environment\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "# Assign values\n",
        "color_1 = '#15466d' # Dark blue\n",
        "\n",
        "# Create the scatter plot with varying marker size\n",
        "scatter = ax.scatter(x,y, s=counts*20, facecolor='white', edgecolor=color_1)\n",
        "\n",
        "# Set x and y limits\n",
        "ax.set(xlim=(21,36))\n",
        "ax.set(ylim=(18,36))\n",
        "\n",
        "# Adding labels\n",
        "# Set the x and y labels\n",
        "ax.set_xlabel('Gestational age (weeks)',fontsize=12)\n",
        "ax.set_ylabel('Head circumference (cm)',fontsize=12)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8cbcLSFuAzr"
      },
      "source": [
        "If the code is correct, you should see the following plot:\n",
        "\n",
        "![____](https://biologicslab.co/BIO5853/images/module_03/lesson_03_9_image24.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9r-vr_ynuAzr"
      },
      "source": [
        "### **Exercise 3: Two-Way Scatter Plot**\n",
        "\n",
        "In the cell below create of two-way scatter plot of the salt/blood pressure data using Python. The independent variable ($x$) should be salt consumption (`salt`) with the dependent variable ($y$) blood pressure (`BP`).\n",
        "\n",
        "Since the `saltDF` DataFrame doesn't have a `count` column, you will need to comment-out or erase it when extracting the x and y values. You will also have to change the plotting code so that `s=50` has a fixed value.\n",
        "\n",
        "~~~text\n",
        "# Create scatter plot with fixed marker size\n",
        "scatter = ax.scatter(x,y, s=50, facecolor='white', edgecolor=color_1)\n",
        "~~~\n",
        "\n",
        "Set your x and y limits to:\n",
        "\n",
        "~~~text\n",
        "# Set x and y limits\n",
        "ax.set(xlim=(-0.5,14))\n",
        "ax.set(ylim=(125,150))\n",
        "~~~\n",
        "\n",
        "Finally, label your x-axis `\"Salt\"` and the y-axis `\"BP\"`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mx70ZtHxuAzr"
      },
      "outputs": [],
      "source": [
        "# Insert your code for Exercise 3 here\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1y052Z_uAzr"
      },
      "source": [
        "If your code is correct, you should see the following plot:\n",
        "\n",
        "![____](https://biologicslab.co/BIO5853/images/module_03/lesson_03_9_image38.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPt5vIEQuAzv"
      },
      "source": [
        "From visual inspection you should see that there is an obvious positive correlation between salt intake (independent variable) and blood pressure (dependent variable)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-lbHrqguAzv"
      },
      "source": [
        "### **Draw an Arbitrary Line**\n",
        "\n",
        "It is probably a natural impulse to want to draw a line through the data points in **Figure 17.5** as a way to visualize the relationship between gestational age (x, the independent variable) and head circumference (y, the dependent variable). One possible \"arbitrary\" line is shown in **Figure 17.6** taken from page 406 in your textbook.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGNngT7VuAzv"
      },
      "source": [
        "![____](https://biologicslab.co/BIO5853/images/module_03/lesson_03_9_image11.png)\n",
        "\n",
        "**FIGURE 17.6**  Arbitrary line depicting a relationship between head circumference and gestational age"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6vL-lJ8uAzv"
      },
      "source": [
        "### Example 4: Two-Way Scatter Plot with Line\n",
        "\n",
        "The code in the cell below shows how to recreate **Figure 17.6** using Python.\n",
        "\n",
        "_Code Decription:_\n",
        "\n",
        "Here is the code chunk that adds an \"arbitrary line\"\n",
        "\n",
        "~~~text\n",
        "# Adding a line to the plot\n",
        "ax.plot(np.unique(x), np.poly1d(np.polyfit(x, y, 1))(np.unique(x)), color='k', linestyle='-')\n",
        "~~~\n",
        "This command is doing quite a bit of work to add a regression line to a plot. Let me break it down for you:\n",
        "\n",
        "1. `np.polyfit(x, y, 1)`:\n",
        "* Fits a polynomial of degree 1 (a straight line) to the data points (x, y).\n",
        "* Returns the coefficients of the best-fit line.\n",
        "\n",
        "2. `np.poly1d(...)`:\n",
        "* Creates a polynomial function with the coefficients found by np.polyfit().\n",
        "3. `np.unique(x):`\n",
        "* Returns the sorted unique elements from array x.\n",
        "* Ensures that the x-values used for plotting are unique and sorted.\n",
        "\n",
        "4. `np.poly1d(...)(np.unique(x))`:\n",
        "* Evaluates the polynomial function at each of the unique x-values.\n",
        "\n",
        "5. `ax.plot(..., color='k', linestyle='-')`:\n",
        "* Plots the evaluated polynomial function (regression line) on the existing axis ax.\n",
        "* The line is black (color='k') and solid (linestyle='-').\n",
        "\n",
        "\n",
        "Here is the code that creates the shorter, vertical line at the right of the main line:\n",
        "\n",
        "~~~text\n",
        "# Define line coord\n",
        "x_line=[35, 35]\n",
        "y_line=[31.16, 29.2]\n",
        "\n",
        "# Plot line\n",
        "plt.plot(x_line,y_line,\n",
        "         color='k',\n",
        "         linestyle='solid',\n",
        "         linewidth=1.0)\n",
        "~~~\n",
        "\n",
        "Finally, here is the code that adds the labels and short lines to the vertical line:\n",
        "\n",
        "~~~text\n",
        "# Adding labels\n",
        "ax.set_xlabel('Gestational age (weeks)',fontsize=12)\n",
        "ax.set_ylabel('Head circumference (cm)',fontsize=12)\n",
        "\n",
        "# Plot text\n",
        "plt.text(34.25, 32, '($x_i$,$y_i$)', fontsize=12)\n",
        "plt.text(34.25, 28., '($x_i$,$y_i$)', fontsize=12)\n",
        "~~~"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aES3x_h3uAzv"
      },
      "outputs": [],
      "source": [
        "# Example 4: Two-Way Scatter Plot with Line\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Assign values\n",
        "color_1 = '#15466d' # Dark blue\n",
        "\n",
        "# Extract x- y-values\n",
        "x = np.array(headDF['gestage'])\n",
        "y = np.array(headDF['headcirc'])\n",
        "counts = np.array(headDF['count'])\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame({'x': x, 'y': y})\n",
        "\n",
        "# Create the scatter plot with varying marker sizes\n",
        "fig, ax = plt.subplots()\n",
        "scatter = ax.scatter(x,y, s=counts*20, facecolor='white', edgecolor=color_1)\n",
        "\n",
        "# Adding labels\n",
        "# Set the x and y labels\n",
        "ax.set_xlabel('Gestational age (weeks)',fontsize=12)\n",
        "ax.set_ylabel('Head circumference (cm)',fontsize=12)\n",
        "\n",
        "# Adding a line to the plot\n",
        "ax.plot(np.unique(x), np.poly1d(np.polyfit(x, y, 1))(np.unique(x)), color='k', linestyle='-')\n",
        "\n",
        "# Set x and y limits\n",
        "ax.set(xlim=(21,36))\n",
        "ax.set(ylim=(20,36))\n",
        "\n",
        "# Define line coord\n",
        "x_line=[35, 35]\n",
        "y_line=[31.16, 29.2]\n",
        "\n",
        "# Plot line\n",
        "plt.plot(x_line,y_line,\n",
        "         color='k',\n",
        "         linestyle='solid',\n",
        "         linewidth=1.0)\n",
        "\n",
        "# Set x and y limits\n",
        "ax.set(xlim=(21,36))\n",
        "ax.set(ylim=(18,36))\n",
        "\n",
        "# Adding labels\n",
        "ax.set_xlabel('Gestational age (weeks)',fontsize=12)\n",
        "ax.set_ylabel('Head circumference (cm)',fontsize=12)\n",
        "\n",
        "# Plot text\n",
        "plt.text(34.25, 32, '($x_i$,$y_i$)', fontsize=12)\n",
        "plt.text(34.25, 28., '($x_i$,$y_i$)', fontsize=12)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKlOQsBZuAzw"
      },
      "source": [
        "If the code is correct, you should see the following plot:\n",
        "\n",
        "![____](https://biologicslab.co/BIO5853/images/module_03/lesson_03_9_image25.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttM65i5_uAzw"
      },
      "source": [
        "### **Exercise 4: Two-Way Scatter Plot with Line**\n",
        "\n",
        "In the cell below create a two-way scatter plot with an arbitrary line for the salt/blood pressure data in the DataFrame `saltDF` using Python.\n",
        "\n",
        "_Code Hints:_\n",
        "\n",
        "For the most part, you can reuse your code from **Exercise 3**.\n",
        "\n",
        "Use the same code chunk from Example 4 to add an \"arbitrary line\" to your plot:\n",
        "\n",
        "~~~text\n",
        "# Adding a line to the plot\n",
        "ax.plot(np.unique(x), np.poly1d(np.polyfit(x, y, 1))(np.unique(x)), color='k', linestyle='-')\n",
        "~~~\n",
        "\n",
        "This should be the only line you add. Don't add the small vertical line and the text. Your plot should only have a single line at an approximately 45 degree angle.\n",
        "\n",
        "Finally, here is the code for the x-, y-limits and titles.\n",
        "\n",
        "~~~text\n",
        "# Set x and y limits\n",
        "ax.set(xlim=(-0.5,14))\n",
        "ax.set(ylim=(125,150))\n",
        "\n",
        "# Set the x and y labels\n",
        "ax.set_xlabel('Salt', fontsize=12)\n",
        "ax.set_ylabel('BP', fontsize=12)\n",
        "~~~"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ksc3AUUFuAzw"
      },
      "outputs": [],
      "source": [
        "# Insert your code for Exercise 4 here\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDaH7EANuAzw"
      },
      "source": [
        "If your code is correct, you should see the following plot:\n",
        "\n",
        "![____](https://biologicslab.co/BIO5853/images/module_03/lesson_03_9_image39.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6CS0XyFuAzw"
      },
      "source": [
        "### **Line of Best Fit**\n",
        "\n",
        "Rather than draw an 'arbitrary' line using our eye, it would be much better to let our computer figure out the very **_best_** line that can be drawn thorough our data points.\n",
        "\n",
        "The **_line of best fit_**, also known as the _regression line_, is a straight line that best represents the data on a scatter plot. It minimizes the distances (residuals) between the observed data points and the line itself, effectively summarizing the relationship between the variables. In statistics, it's derived using the **_ordinary least squares (OLS)_** method, making it a crucial tool for predicting future data points and understanding trends in data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TC9oDDJnuAzw"
      },
      "source": [
        "## **Ordinary Least Squares (OLS) method**\n",
        "\n",
        "When performing linear regression analysis with Python, the `statsmodels.api` can be used. The `statsmodels.api` package is a powerful Python library designed for statistical modeling and hypothesis testing. It's widely used by data analysts and researchers to build and evaluate statistical models. Here are the key features:\n",
        "\n",
        "#### **Key Features:**\n",
        "\n",
        "* **Linear Regression:** Functions for ordinary least squares (OLS) and other types of regression models.\n",
        "* **Time Series Analysis:** Tools for analyzing time series data, including ARIMA and state space models.\n",
        "* **ANOVA:** Analysis of variance techniques.\n",
        "* **Generalized Linear Models (GLM):** For modeling relationships between variables with different types of distributions.\n",
        "* **Statistical Tests:** Hypothesis tests such as t-tests, chi-square tests, and other\n",
        "\n",
        "In Example 4, we will be using the OLS function from this package to perform a regression analysis on the head circumference/gestational age data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6T7LuE1NuAzw"
      },
      "source": [
        "### Example 5: Perform Ordinary Least Squares (OLS)\n",
        "\n",
        "The code in the cell below shows how to perform an **_Ordinary Least Squares (OLS)_** analysis on the head circumference dataset in the DataFrame `headDF` using the `statsmodel.api`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVPp7PlHuAzx"
      },
      "outputs": [],
      "source": [
        "# Example 4: Perform OLS\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Extract x- y-values\n",
        "x = np.array(headDF['gestage'])\n",
        "y = np.array(headDF['headcirc'])\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame({'x': x, 'y': y})\n",
        "\n",
        "# Fit regression model\n",
        "X = sm.add_constant(df['x'])  # Adds a constant term to the predictor\n",
        "model = sm.OLS(df['y'], X).fit()\n",
        "\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhdtfJPduAzx"
      },
      "source": [
        "If the code is correct, you should see the following output:\n",
        "\n",
        "~~~text\n",
        "                            OLS Regression Results                            \n",
        "==============================================================================\n",
        "Dep. Variable:                      y   R-squared:                       0.609\n",
        "Model:                            OLS   Adj. R-squared:                  0.605\n",
        "Method:                 Least Squares   F-statistic:                     152.9\n",
        "Date:                Wed, 09 Oct 2024   Prob (F-statistic):           1.00e-21\n",
        "Time:                        18:40:07   Log-Likelihood:                -187.28\n",
        "No. Observations:                 100   AIC:                             378.6\n",
        "Df Residuals:                      98   BIC:                             383.8\n",
        "Df Model:                           1                                         \n",
        "Covariance Type:            nonrobust                                         \n",
        "==============================================================================\n",
        "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
        "------------------------------------------------------------------------------\n",
        "const          3.9143      1.829      2.140      0.035       0.284       7.544\n",
        "x              0.7801      0.063     12.367      0.000       0.655       0.905\n",
        "==============================================================================\n",
        "Omnibus:                       23.475   Durbin-Watson:                   1.028\n",
        "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               53.083\n",
        "Skew:                           0.849   Prob(JB):                     2.97e-12\n",
        "Kurtosis:                       6.140   Cond. No.                         334.\n",
        "==============================================================================\n",
        "\n",
        "Notes:\n",
        "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
        "~~~"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKieqVviuAzx"
      },
      "source": [
        "As you can see, the complete summary for an OLS model is quite detailed.\n",
        "\n",
        "#### **Key Sections:**\n",
        "\n",
        "##### **Coefficients Table:**\n",
        "\n",
        "* **coef:** These are the estimated coefficients for each predictor variable. They represent the change in the dependent variable for a one-unit change in the predictor variable.\n",
        "* **std err:** This is the standard error of the coefficient estimates. It gives an indication of the variability of the estimates.\n",
        "* **t:** This is the t-statistic for the coefficient. It is calculated as the coefficient divided by its standard error.\n",
        "* **P>|t|:** This is the p-value for the t-test of the null hypothesis that the coefficient is equal to zero. A low p-value (typically < 0.05) indicates that the coefficient is significantly different from zero.\n",
        "* **[0.025 0.975]:** These are the 95% confidence intervals for the coefficient estimates.\n",
        "\n",
        "##### **Model Statistics:**\n",
        "\n",
        "* **R-squared:** This is the proportion of variance in the dependent variable that is explained by the independent variables. It ranges from 0 to 1, with higher values indicating a better fit.\n",
        "* **Adj. R-squared:** This is the adjusted R-squared, which takes into account the number of predictors in the model. It is a more accurate measure of goodness of fit when multiple predictors are involved.\n",
        "* **F-statistic:** This tests the overall significance of the model. It compares the model with no predictors to the specified model. A high F-statistic and a low p-value indicate that the model is significant.\n",
        "\n",
        "##### **Summary Statistics:**\n",
        "\n",
        "* **Prob (F-statistic):** The p-value associated with the F-statistic. It indicates the probability that the observed F-statistic would occur by chance if the null hypothesis were true.\n",
        "* **Log-Likelihood:** This is the log of the likelihood function evaluated at the estimated coefficients. It is used in comparing models.\n",
        "* **AIC (Akaike Information Criterion):** A measure of the relative quality of a statistical model. Lower values indicate a better model.\n",
        "* **BIC (Bayesian Information Criterion):** Similar to AIC, but it includes a penalty term for the number of predictors in the model. Lower values indicate a better model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTbijlvkuAzx"
      },
      "source": [
        "### **Exercise 5: Perform Ordinary Least Squares (OLS)**\n",
        "\n",
        "In the cell below write the Python code to perform an Ordinary Least Squares (OLS) analysis on the salt/blood pressure dataset in the DataFrame `saltDF` using the `statsmodel.api`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ttzm194KuAzx"
      },
      "outputs": [],
      "source": [
        "# Insert your code for Exercise 5 here\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAdq9jM1uAzx"
      },
      "source": [
        "If your code is correct, you should see the following output:\n",
        "\n",
        "~~~text\n",
        "                            OLS Regression Results                            \n",
        "==============================================================================\n",
        "Dep. Variable:                      y   R-squared:                       0.704\n",
        "Model:                            OLS   Adj. R-squared:                  0.691\n",
        "Method:                 Least Squares   F-statistic:                     54.59\n",
        "Date:                Fri, 11 Oct 2024   Prob (F-statistic):           1.63e-07\n",
        "Time:                        09:25:11   Log-Likelihood:                -59.679\n",
        "No. Observations:                  25   AIC:                             123.4\n",
        "Df Residuals:                      23   BIC:                             125.8\n",
        "Df Model:                           1                                         \n",
        "Covariance Type:            nonrobust                                         \n",
        "==============================================================================\n",
        "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
        "------------------------------------------------------------------------------\n",
        "const        128.6164      1.102    116.723      0.000     126.337     130.896\n",
        "x              1.1969      0.162      7.389      0.000       0.862       1.532\n",
        "==============================================================================\n",
        "Omnibus:                        0.432   Durbin-Watson:                   1.846\n",
        "Prob(Omnibus):                  0.806   Jarque-Bera (JB):                0.565\n",
        "Skew:                          -0.226   Prob(JB):                        0.754\n",
        "Kurtosis:                       2.419   Cond. No.                         13.9\n",
        "==============================================================================\n",
        "\n",
        "Notes:\n",
        "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
        "~~~"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_R4QphfpuAzx"
      },
      "source": [
        "From the model summary you can see that the two coefficients needed to construct an the linear model:\n",
        "\n",
        "* `cont 128.6164` is the y-intercept ($\\beta_0$)\n",
        "* `x` is the slope value ($\\beta_1$)\n",
        "\n",
        "For the salt/blood pressue data, then, the linear mode would be:\n",
        "\n",
        "$$ y = 128.6164 + 1.1969 x $$\n",
        "\n",
        "We also know from the `R-squared: 0.704` that this model accounts for about 70% of the differences in the y-values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKH8XVNAuAzy"
      },
      "source": [
        "### **Adding a Regression Line to a Two-Way Scatter Plot**\n",
        "\n",
        "When creating a two-way scatterplot, it is common to add the **_line of best fit_** or _regression line_, especially if the data appears to have a linear relationship. **Figure 17.7** is an example of a two-way scatter plot with a regrssion line added. For Example 6 we will recreate this figure by _manually_ creating the line from its coefficients."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6NLiLn5uAzy"
      },
      "source": [
        "\n",
        "\n",
        "![____](https://biologicslab.co/BIO5853/images/module_03/lesson_03_9_image12.png)\n",
        "\n",
        "**FIGURE 17.7**  Least squares regression of head circumference on gestational age,  $\\hat{y} = 3.9143 + 0.7801x$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2ECJMCquAzy"
      },
      "source": [
        "### Example 6: Manually Adding a Regression Line\n",
        "\n",
        "The code in the cell below adds a regression line to a two-way scatter plot. In this example, the regression line is added by manually entering values for the y-intercept ($\\beta_0$) and the slope ($\\beta_1)$. The code recreates **Figure 17.7**, manually adding the regression line\n",
        "\n",
        "$$\\hat{y} = 3.9143 + 0.7801x$$\n",
        "\n",
        "The appropiate values can be found in the summary output in Example 4:\n",
        "\n",
        "~~~text\n",
        "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
        "------------------------------------------------------------------------------\n",
        "const          3.9143      1.829      2.140      0.035       0.284       7.544\n",
        "x              0.7801      0.063     12.367      0.000       0.655       0.905\n",
        "~~~\n",
        "\n",
        "_Code Description:_\n",
        "\n",
        "The code for generating the basic two-way scatter plot is the same as that used previously in Examples 3 and 4.\n",
        "\n",
        "Here is the code chunk that generates the x values, `line_x`, for the regression line:\n",
        "\n",
        "~~~text\n",
        "# Generate x-values for regression line\n",
        "line_x = np.linspace(x.min(), x.max(), 10)\n",
        "~~~\n",
        "\n",
        "The x-values for the regression line are generated by the numpy function `linspace()`. `numpy.linspace` is a powerful tool for generating evenly spaced values over a specified range. Here's how it works:\n",
        "\n",
        "1. **start:** The starting value of the sequence.\n",
        "2. **stop:** The end value of the sequence.\n",
        "3. **num:** The number of values to generate.\n",
        "\n",
        "By setting **start** = `x.min(x)` and **stop** = `x.max()` our regression line will start at the smallest x-value and end with the largest x-value.\n",
        "\n",
        "Once we have defined the `x-line` values, we can compute the `line_y` values using this code chunk:\n",
        "\n",
        "~~~text\n",
        "# Generate a y-value for each x-value\n",
        "line_y = beta_0 + beta_1 * line_x\n",
        "~~~\n",
        "\n",
        "For each `line_x` value, the equation computes the corresponding `line_y` value.\n",
        "\n",
        "The regression line is plotted with this code chunk:\n",
        "\n",
        "~~~text\n",
        "# Plot regression line\n",
        "ax.plot(line_x,line_y, c='k')\n",
        "~~~"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BAyVjKO9uAzy"
      },
      "outputs": [],
      "source": [
        "# Example 6: Manually Adding a Regression Line\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Manually enter coefficients from Example 5\n",
        "beta_0 = 3.9143\n",
        "beta_1 = 0.7801\n",
        "\n",
        "# Extract x- y-values\n",
        "x = np.array(headDF['gestage'])\n",
        "y = np.array(headDF['headcirc'])\n",
        "counts = np.array(headDF['count'])\n",
        "\n",
        "# Generate x-values for regression line\n",
        "line_x = np.linspace(x.min(), x.max(), 10)\n",
        "\n",
        "# Generate a y-value for each x-value\n",
        "line_y = beta_0 + beta_1 * line_x\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame({'x': x, 'y': y})\n",
        "\n",
        "# Define color from textbook\n",
        "color_1 = '#15466d' # Dark blue\n",
        "\n",
        "# Create the scatter plot with varying marker sizes\n",
        "fig, ax = plt.subplots()\n",
        "scatter = ax.scatter(x,y, s=counts*20, facecolor='white', edgecolor=color_1)\n",
        "\n",
        "# Plot regression line\n",
        "ax.plot(line_x,line_y, c='k')\n",
        "\n",
        "# Set x and y limits\n",
        "ax.set(xlim=(21,36))\n",
        "ax.set(ylim=(18,36))\n",
        "\n",
        "# Adding labels\n",
        "# Set the x and y labels\n",
        "ax.set_xlabel('Gestational age (weeks)',fontsize=12)\n",
        "ax.set_ylabel('Head circumference (cm)',fontsize=12)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9Vbl16PuAzy"
      },
      "source": [
        "If the code is correct, you should see the following plot:\n",
        "\n",
        "![____](https://biologicslab.co/BIO5853/images/module_03/lesson_03_9_image26.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiUAat0cuAzy"
      },
      "source": [
        "### **Exercise 6: Manually Adding a Regression Line**\n",
        "\n",
        "In the cell below, add a regression line to a two-way scatter plot of your salt/blood pressure data. Manually enter the coefficients for the y-intercept ($\\beta_0$) and the slope ($\\beta_1)$ that you calculated in **Exercise 5**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtqbgVcCuAzy"
      },
      "outputs": [],
      "source": [
        "# Example 6: Manually Adding a Regression Line\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaLMHwvduAzy"
      },
      "source": [
        "If your code is correct, you should see the following plot:\n",
        "\n",
        "![____](https://biologicslab.co/BIO5853/images/module_03/lesson_03_9_image40.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzqAT1WWuAzy"
      },
      "source": [
        "\n",
        "\n",
        "![____](https://biologicslab.co/BIO5853/images/module_03/lesson_03_9_image14.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykvhDrrpuAzz"
      },
      "source": [
        "## **Inference for Predicted Values**  \n",
        "\n",
        "In addition to making inference about the population slope and intercept, we might also be interested in using the least squares regression line to estimate the mean value of y corresponding to a particular value of x, and to construct a 95% confidence interval for this mean. If we have a sample of 100  observations, for instance, the confidence interval will take the form  \n",
        "\n",
        "$$ (\\hat{y} - 1.98 \\, \\text{se}(\\hat{y}), \\hat{y} + 1.98 \\, \\text{se}(\\hat{y}))$$\n",
        "\n",
        "\n",
        "where $\\hat{y}$ is the predicted mean of the normally distributed outcomes, and the standard error of $\\hat{y}$ is estimated by  \n",
        "\n",
        "$$  \\hat{\\text{se}}(\\hat{y}) = s_{y|x} \\sqrt{\\left[ \\frac{1}{n} + \\frac{(x - \\bar{x})^2}{\\sum_{i=1}^{n} (x_i - \\bar{x})^2} \\right]}.\n",
        "$$\n",
        "\n",
        "Note the term $(x - x^2)$ 2 in the formula for the standard error. This quantity takes the value 0 when  $x$ is equal to $\\bar{x}$, and gets larger as $x$ moves farther and farther away. As a result, if $x$ is near $\\bar{x}$, the  confidence interval is relatively narrow. It grows wider as $x$ moves away from $\\bar{x}$. Intuitively, we are  more confident about the mean value of the response when we are closer to the mean value of the  explanatory variable.  \n",
        "\n",
        ">Pagano, Marcello; Gauvreau, Kimberlee; Mattie, Heather. Principles of Biostatistics (p. 410). CRC Press. Kindle Edition."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUUZtmubuAzz"
      },
      "source": [
        "## **95% Confidence Limits**\n",
        "\n",
        "Your textbook discusses two ways you can add confidence limits to a two-ways scatter plot. **Figure 17.9** shows 95% confidence limits on individual predicted $y$ for a given $x$. The confidence limits are curved, not straight. Confidence limits around a regression line are curved because they reflect the variability of the predicted values, which **_increases_** as you move away from the mean of the predictor variables. In essence, the farther you get from the center of your data, the less certain your predictions become, leading to those characteristic curves. It's all about accounting for the underlying uncertainty in your model's predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Vrd4VJouAzz"
      },
      "source": [
        "\n",
        "\n",
        "![____](https://biologicslab.co/BIO5853/images/module_03/lesson_03_9_image22.png)\n",
        "\n",
        "**Figure 17.9** The 95% confidence limits on an individual predicted $y$ for a given value of $x$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlYmpeyDuAzz"
      },
      "source": [
        "### Example 7: Adding Confidence Limits to the Regression Line\n",
        "\n",
        "The code in the cell below recreates **Figure 17.9** by adding 95% confidence limits.\n",
        "\n",
        "_Code Description:_\n",
        "\n",
        "In order to add confidence intervals, it is first necessary to perform a OLS analysis to generate a `model`:\n",
        "\n",
        "~~~text\n",
        "# Generate OLS model\n",
        "X = sm.add_constant(x)  # Adds a constant term to the predictor\n",
        "model = sm.OLS(y, X).fit()\n",
        "~~~\n",
        "\n",
        "The model is used to generate the y-values for the regression line with this code chunk:\n",
        "~~~text\n",
        "line_y = model.predict(X)\n",
        "~~~\n",
        "\n",
        "The model is then used to generate the confidence intervals using this code chunk:\n",
        "\n",
        "~~~text\n",
        "# Calculate confidence intervals\n",
        "prstd, iv_l, iv_u = wls_prediction_std(model)\n",
        "~~~\n",
        "This line of code calculates the standard error and the prediction intervals for the weighted least squares (WLS) regression model. Breaking it down:\n",
        "\n",
        "* **prstd:** Standard error of the prediction.\n",
        "* **iv_l:** Lower bound of the prediction interval.\n",
        "* **iv_u:** Upper bound of the prediction interval.\n",
        "\n",
        "These values are then added to the plot with this line of code:\n",
        "~~~text\n",
        "# Plot confidence intervals\n",
        "ax.plot(df['x'],iv_l,color='k', linewidth=1)\n",
        "ax.plot(df['x'],iv_u,color='k', linewidth=1)\n",
        "~~~\n",
        "\n",
        "In this example, the coefficients for the regression were calculated **_automatically_** as part of the OLS model so there's no need to enter them manually. Here is the code chunk that plots the regression line:\n",
        "\n",
        "~~~text\n",
        "# Plot regression line\n",
        "plt.plot(x, line_y, color='k')\n",
        "~~~\n",
        "\n",
        "As stated above, the variable `line_y` contains the y-values for the regression line."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "syNh7eiVuAzz"
      },
      "outputs": [],
      "source": [
        "# Example 7: Adding Confidence Limits to the Regression Line\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.sandbox.regression.predstd import wls_prediction_std\n",
        "\n",
        "# Extract x- y-values\n",
        "x = np.array(headDF['gestage'])\n",
        "y = np.array(headDF['headcirc'])\n",
        "counts = np.array(headDF['count'])\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame({'x': x, 'y': y})\n",
        "\n",
        "# Generate OLS model\n",
        "X = sm.add_constant(x)  # Adds a constant term to the predictor\n",
        "model = sm.OLS(y, X).fit()\n",
        "\n",
        "# Generate y-values for regression line\n",
        "line_y = model.predict(X)\n",
        "\n",
        "# Calculate confidence intervals\n",
        "prstd, iv_l, iv_u = wls_prediction_std(model)\n",
        "\n",
        "# Create plotting environment\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "\n",
        "# Assign color value\n",
        "color_1 = '#15466d' # Dark blue\n",
        "\n",
        "# Plot scatter plot\n",
        "ax.scatter(df['x'], df['y'],\n",
        "           s=counts*20,\n",
        "           facecolor='white',\n",
        "           edgecolor=color_1)\n",
        "\n",
        "# Plot regression line\n",
        "plt.plot(x, line_y, color='k')\n",
        "\n",
        "# Plot confidence intervals\n",
        "ax.plot(df['x'],iv_l,color='k', linewidth=1)\n",
        "ax.plot(df['x'],iv_u,color='k', linewidth=1)\n",
        "\n",
        "# Set x and y limits\n",
        "ax.set(xlim=(21,36))\n",
        "ax.set(ylim=(18,36))\n",
        "\n",
        "# Adding labels\n",
        "ax.set_xlabel('Gestational age (weeks)',fontsize=12)\n",
        "ax.set_ylabel('Head circumference (cm)',fontsize=12)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4D36UKIhuAzz"
      },
      "source": [
        "If the code is correct, you should see the following plot:\n",
        "\n",
        "![____](https://biologicslab.co/BIO5853/images/module_03/lesson_03_9_image21.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnAamFDCuAzz"
      },
      "source": [
        "You should note that there is one value that is below the lower 95% confidence limit and two values that are outside of the upper 95% confidence limit. Since we are the are 100 infants in this sample, the **_Emprical Rule_** tells us to expect at least one value outside of the confidence limits. Howerver, the two values above the upper limit (gestational age = 31) appear to be **_outliers_**. An _outlier_ is a data point that diverges markedly from the overall pattern of data. In statistics, outliers can significantly affect the results of an analysis. They may indicate variability in measurements, errors in data collection, or the presence of a novel, previously unnoticed phenomenon. Identifying and handling outliers is crucial as they can skew data analysis, leading to potentially misleading conclusions.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxuenOhhuAz0"
      },
      "source": [
        "### **Exercise 7: Adding Confidence Limits to the Regression Line**\n",
        "\n",
        "In the cell below, write the code to add 95% confidence limits to your two-way scatter plot of the salt/blood pressure data.\n",
        "\n",
        "_Code Hints:_\n",
        "\n",
        "Here are the x- and y-limits:\n",
        "\n",
        "~~~text\n",
        "# Set x and y limits\n",
        "ax.set(xlim=(-0.5,14))\n",
        "ax.set(ylim=(120,155))\n",
        "~~~\n",
        "\n",
        "These limits expand the plot so the ends of the 95% confidence limits are visible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4d3oqCrguAz0"
      },
      "outputs": [],
      "source": [
        "# Insert your code for Exercise 7 here\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zGHYhBmuAz0"
      },
      "source": [
        "If the code is correct, you should see the following plot:\n",
        "\n",
        "![____](https://biologicslab.co/BIO5853/images/module_03/lesson_03_9_image41.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpZEGB4MuAz0"
      },
      "source": [
        "## **Evaluation of the Model**  \n",
        "\n",
        "After generating a least squares regression line represented by  $\\hat{y} = \\hat\\beta_0 + \\hat\\beta_1x$,  we might wonder how well this model actually fits the observed data. Is it a good model? There are  several methods available to help evaluate the fit of a linear regression model.\n",
        "\n",
        "### **Coefficient of Determination**\n",
        "\n",
        "One way to get a sense of the fit is to compute the coefficient of determination. The coefficient of determination is represented by $R^2$, and is the square of the Pearson correlation coefficient $r$ between $Y$ and $X$; consequently,  $r^2 = R^2$.  Since _r_ can assume any value in the range −1 to 1, $R^2$ must lie between 0 and 1. If $R^2$ = 1, all  of the data points in the sample fall directly on the least squares line. If $R^2$ = 0, there is no linear  relationship between x and y. The coefficient of determination can be interpreted as the proportion of the variability among the observed values of $y$ that is explained by the linear regression of $y$ on $x$. This interpretation derives from the relationship between $\\sigma_y $, the standard deviation of the outcomes of the response variable $Y$, and $\\sigma_y |x$, the standard deviation of $y$ for a specified value of the explanatory variable $X$, that was presented in Section 17.1:  \n",
        "\n",
        "From the relationship between $(\\sigma_{y|x}$), the standard deviation of the outcomes of the response variable $(Y$), and $(\\sigma_{y|x}$), the standard deviation of $(y$) for a specified value of the explanatory variable $(X$), that was presented in Section 17.1:\n",
        "\n",
        "$$\\sigma_{y|x}^2 = (1 - \\rho^2) \\sigma_y^2. $$\n",
        "\n",
        "Recall that ($\\rho$) is the correlation between $(X$) and $(Y$) in the underlying population. If we replace \\(\\sigma_y\\) and \\(\\sigma_{y|x}\\) by their estimators – the sample standard deviations $(s_y$) and $(s_{y|x}$) – and $(\\rho$) by the Pearson correlation coefficient $(r$), we have\n",
        "\n",
        "$$\n",
        "s_{y|x}^2 = (1 - r^2) s_y^2 = (1 - R^2) s_y^2.\n",
        "$$\n",
        "\n",
        "Solving this equation for $(R^2$),\n",
        "\n",
        "$$\n",
        "R^2 = 1 - \\frac{s_{y|x}^2}{s_y^2} = \\frac{s_y^2 - s_{y|x}^2}{s_y^2}.\n",
        "$$\n",
        "\n",
        "Since $( s^2_{y|x} $) is the variation in the $( y $) values that still remains after accounting for the linear relationship between $( y $) and $( x $), $( s^2_y - s^2_{y|x} $) must be the variation in $( y $) that is explained by this relationship. Thus, $( R^2 $) is the proportion of the total observed variability among the $( y $) values that is explained by the linear regression of $( y $) on $( x $).\n",
        "\n",
        "For the regression of head circumference on gestational age, the coefficient of determination can be shown to be\n",
        "\n",
        "$$ R^2 = 0.6095.$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0MoISbOuAz0"
      },
      "source": [
        "### Example 8: Compute $R^2$\n",
        "\n",
        "The code in the cell below uses the function `sm.OLS()` from the `statsmodels` library in Python for performing ordinary least squares (OLS) regression. We will use Python to calculate the regression of head circumference on gestational age and see if we get the same value for $R^2 = 0.6095.$\n",
        "\n",
        "_Code Description:_\n",
        "\n",
        "Here is an explanation of the code:\n",
        "\n",
        "* **Import Libraries:** `statsmodels.api` for OLS regression, numpy and pandas for data handling.\n",
        "* **Extract Data:** Extract x- and y-values from DataFrame.\n",
        "* **Create DataFrame:** Creates a DataFrame to hold the extracted x- and y-values\n",
        "* **Add Constant:** `sm.add_constant(df['x'])` adds an intercept term to the model.\n",
        "* **Fit the Model:** `sm.OLS(df['y'], X).fit()` fits the OLS model to the data. The `.fit()` method performs the regression.\n",
        "* **Extract Results:** `model.summary()` provides a detailed summary of the model, including coefficients, R-squared value, p-values, and more.\n",
        "* **Extract R-squared value:** `r_squared = model.rsquared` instead of printing out the entire summary, you can use this method to extract selective items such as $R^2$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "ukOYZJpPuAz0"
      },
      "outputs": [],
      "source": [
        "# Example 8; Compute r-squared\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Extract x- y-values\n",
        "x = np.array(headDF['gestage'])\n",
        "y = np.array(headDF['headcirc'])\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame({'x': x, 'y': y})\n",
        "\n",
        "# Fit regression model\n",
        "X = sm.add_constant(df['x'])  # Adds a constant term to the predictor\n",
        "model = sm.OLS(df['y'], X).fit()\n",
        "\n",
        "# Extract R-squared value\n",
        "r_squared = model.rsquared\n",
        "\n",
        "# Print header\n",
        "print(\"-----Computing R\\2\\u00B2 -----------------------------\")\n",
        "\n",
        "# Print R-squared value\n",
        "print(f\"R\\2\\u00B2: {r_squared:.4f}\")\n",
        "print(\" \")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7Czq_yLuAz0"
      },
      "source": [
        "If the code is correct, you should see the following output:\n",
        "~~~text\n",
        "-----Computing R² -----------------------------\n",
        "R²: 0.6095\n",
        "~~~"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fE_lWkpZuAz0"
      },
      "source": [
        "### **Exercise 8: Compute $R^2$**\n",
        "\n",
        "In the cell below, compute the value for $R^2$ for the salt/blood pressure dataset.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "dBvfxvIruAz1"
      },
      "outputs": [],
      "source": [
        "# Insert your code for Exercise 8 here\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNLFo8DkuAz1"
      },
      "source": [
        "If your code is correct, you should see the following output:\n",
        "~~~text\n",
        "-----Computing R² -----------------------------\n",
        "R²: 0.7036\n",
        "~~~"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrAwFMKNuAz1"
      },
      "source": [
        "It should be noted that you have already computed $R^2$ for this dataset in **Exercise 5** which was shown in the top line of the summary printout:\n",
        "\n",
        "~~~text\n",
        "                            OLS Regression Results                            \n",
        "==============================================================================\n",
        "Dep. Variable:                      y   R-squared:                       0.704\n",
        "\n",
        "~~~\n",
        "\n",
        "What this example illustrates is how you can extract individual regression values from the `model`. For example, the $R^2$ value was accessed above by the code chunk:\n",
        "\n",
        "~~~text\n",
        "# Extract R-squared value\n",
        "r_squared = model.rsquared\n",
        "~~~\n",
        "\n",
        "Here is a summary of several key values and statistics that can be extracted from a fitted OLS (Ordinary Least Squares) model in statsmodels:\n",
        "\n",
        "##### **Parameters:**\n",
        "* **model.params:** The estimated coefficients.\n",
        "\n",
        "##### **Standard Errors:**\n",
        "* **model.bse:** The standard errors of the estimated coefficients.\n",
        "\n",
        "##### **P-values:**\n",
        "* **model.pvalues:** The p-values for the hypothesis tests of each coefficient.\n",
        "\n",
        "##### **R-squared:**\n",
        "* **model.rsquared:** The coefficient of determination.\n",
        "* **model.rsquared_adj:** Adjusted R-squared.\n",
        "\n",
        "##### **F-statistic:**\n",
        "* **model.fvalue:** The F-statistic of the overall significance of the model.\n",
        "* **model.f_pvalue:** The p-value associated with the F-statistic.\n",
        "\n",
        "##### **Predictions:**\n",
        "* **model.predict():** Predicted values of the model.\n",
        "\n",
        "##### **Residuals:**\n",
        "* **model.resid:** Residuals of the model.\n",
        "\n",
        "##### **Variance-Covariance Matrix:**\n",
        "* **model.cov_params():** The variance-covariance matrix of the estimated coefficients.\n",
        "\n",
        "##### **Log-Likelihood:**\n",
        "* **model.llf:** The log-likelihood of the model.\n",
        "\n",
        "##### **AIC and BIC:**\n",
        "* **model.aic:** Akaike Information Criterion.\n",
        "\n",
        "* **model.bic:** Bayesian Information Criterion.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMltgJn7uAz1"
      },
      "source": [
        "\n",
        "\n",
        "![____](https://biologicslab.co/BIO5853/images/module_03/lesson_03_9_image16.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lsuNaUhuAz1"
      },
      "source": [
        "## **Residual Plots**  \n",
        "\n",
        "Another strategy for evaluating how well the least squares regression line fits the observed data in  the sample used to construct it – focusing in particular on whether the assumptions of the linear  model are met – is to generate a two-way scatter plot of the **_residuals against the fitted values_** of the response variable. **Figure 17.10** on page 415 shows this type of plot."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yATjJMxjuAz1"
      },
      "source": [
        "![____](https://biologicslab.co/BIO5853/images/module_03/lesson_03_9_image28.png)\n",
        "\n",
        "**FIGURE 17.10** Residuals versus fitted values of head circumference."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVwABCpkuAz1"
      },
      "source": [
        "### Example 9: Residual Plot\n",
        "\n",
        "The code in the cell below recreates **Figure 17.10** using Python.\n",
        "\n",
        "_Code Description:_\n",
        "\n",
        "To obtain the fitted-values for the head circumference and their corresponding residual value, we need to perform an `OLS()` analysis using this code chunk:\n",
        "\n",
        "~~~text\n",
        "# Fit regression model\n",
        "X = sm.add_constant(df['x'])  # Adds a constant term to the predictor\n",
        "model = sm.OLS(df['y'], X).fit()\n",
        "~~~\n",
        "\n",
        "Once we have generated the variable `model`, we can extract from it the information we need for our two-way scatter plot using this code chunk:\n",
        "\n",
        "~~~text\n",
        "# Compute fitted values for y from model\n",
        "fitted_y = model.predict(X)\n",
        "~~~"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Y14ppQ-uAz1"
      },
      "outputs": [],
      "source": [
        "# Example 9: Residual Plot\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Extract x- y-values\n",
        "x = np.array(headDF['gestage'])\n",
        "y = np.array(headDF['headcirc'])\n",
        "counts = np.array(headDF['count'])\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame({'x': x, 'y': y})\n",
        "\n",
        "# Fit regression model\n",
        "X = sm.add_constant(df['x'])  # Adds a constant term to the predictor\n",
        "model = sm.OLS(df['y'], X).fit()\n",
        "\n",
        "# Compute fitted values for y from model\n",
        "fitted_y = model.predict(X)\n",
        "\n",
        "# Compute residual by substraction\n",
        "residuals = df['y'] - fitted_y\n",
        "\n",
        "# Create plotting environment\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "\n",
        "# Assign color value\n",
        "color_1 = '#15466d' # Dark blue\n",
        "\n",
        "# Plot residuals\n",
        "ax.scatter(fitted_y, residuals,\n",
        "           s=counts*100,\n",
        "           facecolor='white',\n",
        "           edgecolor=color_1)\n",
        "\n",
        "# Set x and y limits\n",
        "ax.set(xlim=(20,32))\n",
        "ax.set(ylim=(-8,8))\n",
        "\n",
        "# Add labels\n",
        "ax.set_xlabel('Fitted value of head circumference', fontsize=12)\n",
        "ax.set_ylabel('Residual', fontsize=12)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ql1VM5PQuAz2"
      },
      "source": [
        "If the code is correct, you should see the following plot:\n",
        "\n",
        "![____](https://biologicslab.co/BIO5853/images/module_03/lesson_03_9_image42.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJqOtMu4uAz2"
      },
      "source": [
        "A plot of the residuals serves three purposes. First, it can help us to detect outlying observations in the sample. In Figure **17.10**, one residual in particular is somewhat larger than the others; this point is associated with a child whose gestational age is 31 weeks and whose head circumference is 35 cm. We would predict the infant’s head circumference to be only\n",
        "\n",
        "$$ \\hat{y} = 3.914 + 0.7801 \\times 31 = 28.10 \\, \\text{cm.} $$\n",
        "\n",
        "The method of least squares can be very sensitive to such outliers in the data, especially if they correspond to relatively large or relatively small values of $x$. When it is believed that an outlier is the result of an error in measuring or recording a particular observation, removal of this point improves the fit of the regression line. However, care must be taken not to throw away unusual data points that are in fact valid; these observations might be the most interesting ones in the data set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cB7ap72NuAz2"
      },
      "source": [
        "### **Exercise 9: Residual Plot**\n",
        "\n",
        "In the cell below create a residual plot for the salt/blood pressure dataset.\n",
        "\n",
        "_Code Hints:_\n",
        "\n",
        "1. Set the size argument `s=100` for the `ax.scatter()` command.\n",
        "2. Comment out the x- and y-limits. This will let `Matplotlib` select its own values.\n",
        "3. Change the x-label to 'Fitted BP values'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdNNhdBRuAz2"
      },
      "outputs": [],
      "source": [
        "Insert your code for Exercise 9 here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fk4qn7AsuAz2"
      },
      "source": [
        "If your code is correct, you should see the following plot:\n",
        "\n",
        "![____](https://biologicslab.co/BIO5853/images/module_03/lesson_03_9_image44.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnFfj8FzuAz2"
      },
      "source": [
        "A plot of the residuals serves three purposes. First, it can help us to detect outlying observations in the sample. In Figure **17.10**, one residual in particular is somewhat larger than the others; this point is associated with a child whose gestational age is 31 weeks and whose head circumference is 35 cm. We would predict the infant’s head circumference to be only\n",
        "\n",
        "$$ \\hat{y} = 3.914 + 0.7801 \\times 31 = 28.10 \\, \\text{cm.} $$\n",
        "\n",
        "The method of least squares can be very sensitive to such outliers in the data, especially if they correspond to relatively large or relatively small values of $x$. When it is believed that an outlier is the result of an error in measuring or recording a particular observation, removal of this point improves the fit of the regression line. However, care must be taken not to throw away unusual data points that are in fact valid; these observations might be the most interesting ones in the data set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tl00IbhZuAz2"
      },
      "source": [
        "### **Homoscedasticity and Heteroscedasticity**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2on4Gy7puAz2"
      },
      "source": [
        "A plot of the residuals can also suggest a failure in the assumption of homoscedasticity. Recall that homoscedasticity means that the standard deviation of the outcomes $y_i$ or $\\sigma_{y|x}$ is constant, across all values of $x$. If the range of the magnitudes of the residuals either increases or decreases as $x$ gets larger, producing a fan-shaped scatter such as the one in **Figure 17.11**, this implies **_heteroscedasticity_**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uz45rj4LuAz2"
      },
      "source": [
        "![____](https://biologicslab.co/BIO5853/images/module_03/lesson_03_9_image17.png)\n",
        "\n",
        "**FIGURE 17.11** Violation of the assumption of homoscedasticity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTR1FIl9uAz2"
      },
      "source": [
        "### Example 10: Plot of _Heteroscedasticity_\n",
        "\n",
        "The code in the cell below recreates **Figure 17.11** using Python. It is virtually impossible to recreate an exact copy of this plot since a random number generator is used in generating the y-values. However, the code does create a plot where the data exhibits the property of  _heteroscedasticity_.\n",
        "\n",
        "_Code Description:_\n",
        "\n",
        "Since we are using a random number generator, we first set the random seed to a specific value so the result can be repeated\n",
        "\n",
        "~~~text\n",
        "# Set seed for reproducibility\n",
        "np.random.seed(6)  \n",
        "~~~\n",
        "\n",
        "The x-values for the plot are generated in the usual way using the `linspace()` function\n",
        "\n",
        "~~~text\n",
        "# Generate x values\n",
        "x = np.linspace(0, 5, 32)\n",
        "~~~\n",
        "\n",
        "Once the x-values have been generated, we can use the next code chunk to generate the y-values using the following code chunk:\n",
        "\n",
        "~~~text\n",
        "# Generate y values with increasing values\n",
        "y = 0.2 * x + 1 + np.random.normal(scale=3.1 * x, size=x.size)\n",
        "~~~\n",
        "\n",
        "This code snippet is generating $y$ values that follow a linear relationship with $x$ but with increasing variability (heteroscedasticity) as $x$ increases.\n",
        "\n",
        "#### **Breakdown:**\n",
        "\n",
        "1. **Linear Relationship:** `y = 0.2x + 1`\n",
        "* This part creates a linear relationship where the slope is `0.2` and the y-intercept is `1`.\n",
        "\n",
        "2. **Random Normal Noise:** `np.random.normal(scale=3.1 * x, size=x.size)`\n",
        "* This adds normally distributed random noise to the $y$ values.\n",
        "* The scale parameter 3.1 * $x$ makes the standard deviation of the noise increase with $x$, causing the variance of $y4 to grow as $x$\n",
        "\n",
        "3. **Combined Equation:**\n",
        "* $y = 0.2x + 1 + \\epsilon$\n",
        "Where $\\epsilon$ is the normally distributed random noise with a standard deviation proportional to $x$.\n",
        "\n",
        "This creates a dataset with heteroscedasticity, which can be useful for testing how regression models handle non-constant variance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m60mc1AWuAz3"
      },
      "outputs": [],
      "source": [
        "# Example 10: Plot of Heteroscedasticity\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Set seed for reproducibility\n",
        "np.random.seed(6)\n",
        "\n",
        "# Generate x values\n",
        "x = np.linspace(0, 5, 32)\n",
        "\n",
        "# Generate y values with increasing values\n",
        "y = 0.2 * x + 1 + np.random.normal(scale=3.1 * x, size=x.size)\n",
        "\n",
        "# Create the plotting environment\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "\n",
        "# Assign color values\n",
        "color_1 = '#15466d' # Dark blue\n",
        "\n",
        "# Plot the data and the residuals\n",
        "ax.scatter(x, y, edgecolor=color_1, facecolor='none')\n",
        "\n",
        "# Plot the zero horizontal line\n",
        "plt.axhline(y=0, color='k', linestyle='-')\n",
        "\n",
        "# Remove all x tick marks\n",
        "ax.set_xticks([])\n",
        "\n",
        "# Customize y-axis tick marks\n",
        "ax.set_yticks([0])   # set 1 tick at 0\n",
        "ax.set_yticklabels(['0'])  # label tick \"0\"\n",
        "\n",
        "# Set x and y limits\n",
        "ax.set(xlim=(-0.1,5.2))\n",
        "#ax.set(ylim=(-8,8))\n",
        "\n",
        "# Adding labels\n",
        "ax.set_xlabel('Fitted value of $y$', fontsize=12)\n",
        "ax.set_ylabel('Residual', fontsize=12)\n",
        "\n",
        "# Show plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZDKLJpIuAz3"
      },
      "source": [
        "If the code is correct, you should see the following plot:\n",
        "\n",
        "![____](https://biologicslab.co/BIO5853/images/module_03/lesson_03_9_image29.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aunuy_UCuAz3"
      },
      "source": [
        "### **Exercise 10: Plot of _Homoscedasticity_**\n",
        "\n",
        "In the cell below write the code for generating a plot showing Homooscedasticity using Python.\n",
        "\n",
        "_Code Hints:_\n",
        "\n",
        "Since we are using a random number generator, we first set the random seed to a specific value so the result can be repeated\n",
        "\n",
        "~~~text\n",
        "# Set random seed\n",
        "np.random.seed(2)\n",
        "~~~\n",
        "\n",
        "Use this code to generate the x values:\n",
        "\n",
        "~~~text\n",
        "# Generate x values\n",
        "x = np.linspace(0, 10, 30)\n",
        "~~~\n",
        "\n",
        "Once the x-values have been generated, we can use the next code chunk to generate the y-values using the following code chunk:\n",
        "\n",
        "~~~text\n",
        "# Generate y values\n",
        "y = np.random.normal(0, 1, 30)\n",
        "~~~\n",
        "\n",
        "This code snippet is generating random $y$ values that simply follow a normal distribution, neither increasing nor decreasing as $x$ increases.\n",
        "\n",
        "Finally, comment out the line of code that sets the `y-limits`. Both the x-limits and the y-limits should be commented out."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KjM25xtRuAz3"
      },
      "outputs": [],
      "source": [
        "# Insert your code for Exercise 10 here\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGEMc3P9uAz3"
      },
      "source": [
        "If your code is correct, you should see the following plot:\n",
        "\n",
        "![____](https://biologicslab.co/BIO5853/images/module_03/lesson_03_9_image45.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeZKu_BruAz3"
      },
      "source": [
        "By visual inspection you should see that the distribution of `Residual` values doesn't show any obvious change as the value of $x$ increases. We wouldn't expect any systematic change since the \"residuals\" ($y$ values) were randomly generated to fall somewhere within a normal distribution. In other words, this plot illustrates what you should expect to see if your dataset exhibits **_homoscedasticity_**. Remember, your data needs to exhibit homoscedasticity for the results of the OLS analysis to be valid."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfu-NLX-uAz3"
      },
      "source": [
        "## **Transformations**  \n",
        "\n",
        "Consider **Figure 17.12**. This graph is a two-way scatter plot of crude birth rate per 1000 population versus gross domestic product (GDP) per capita for 241 countries around the world. The GDP is  expressed in United States dollars. Note that birth rate decreases as GDP increases. The relationship,  however, is not a linear one. Instead, birth rate drops off rapidly at first; when the GDP per capita reaches approximately $15,000, and then begins to level off. Consequently, if we wish to describe the relationship between birth rate and GDP, we cannot use simple linear regression without applying  some type of transformation first.\n",
        "\n",
        ">Pagano, Marcello; Gauvreau, Kimberlee; Mattie, Heather. Principles of Biostatistics (p. 416). CRC Press. Kindle Edition."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ww5FoCzsuAz3"
      },
      "source": [
        "\n",
        "\n",
        "![____](https://biologicslab.co/BIO5853/images/module_03/lesson_03_9_image18.png)\n",
        "\n",
        "**FIGURE 17.12** Birth rate per 1000 population versus GDP per capita for 241 countries, 2015."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfjBTKqWuAz3"
      },
      "source": [
        "### Example 11A: Transformation - Step 1\n",
        "\n",
        "The code in the cell below recreates **Figure 17.12**. The code is the same Python code that you would use to generate a two-scatter plot. The $x$ values are the values in the column `gdp` in the DataFrame `gdpDF` that was created at the beginning of this lesson. The $y$ values are the values in the column `birthrt`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "rtl0YLryuAz4"
      },
      "outputs": [],
      "source": [
        "# Example 11A: Data Transformation - Step 1\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Extract x- y-values\n",
        "x = np.array(gdpDF['gdp'])\n",
        "y = np.array(gdpDF['birthrt'])\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame({'x': x, 'y': y})\n",
        "\n",
        "# Create a plotting environment\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "# Assign color values\n",
        "color_1 = '#15466d' # Dark blue\n",
        "\n",
        "# Create the scatter plot\n",
        "scatter = ax.scatter(x,y, s=20, facecolor='white', edgecolor=color_1)\n",
        "\n",
        "# Set x and y limits\n",
        "ax.set(xlim=(-5000,200000))\n",
        "ax.set(ylim=(0,50))\n",
        "\n",
        "# Adding labels\n",
        "# Set the x and y labels\n",
        "ax.set_xlabel('GDP per capita (U.S. dollars)',fontsize=12)\n",
        "ax.set_ylabel('Birth rate per 1,000 population',fontsize=12)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSr9alAduAz4"
      },
      "source": [
        "If your code is correct, you should see the following output:\n",
        "\n",
        "![____](https://biologicslab.co/BIO5853/images/module_03/lesson_03_9_image31.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VpXllPRuAz4"
      },
      "source": [
        "As you can see, the relationship is definitely not linear. In situations like this, you should try to find a **_transformation_** that can be applied to the data to make a the x/y relationship more linear. When selecting a suitable transformation, you should focus on _why_ the relationship looks non-linear. In this case, the effect of $x$ on $y$ diminishes as $x$ increases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kako6gCwuAz4"
      },
      "source": [
        "## **Data Transformations**\n",
        "\n",
        "There are a wide variety of transformations that can be applied to data to make the relationship between x and y more linear. To create a linear relationship between $x$ and $y$, the following transformations are commonly used in statistics:\n",
        "\n",
        "**_Logarithmic Transformation:_**\n",
        "\n",
        "* **Log-Linear Model:** $y = \\beta_0  + \\beta_1 log(x) + ϵ$\n",
        "\n",
        "* * Useful when the effect of $x$ on $y$ diminishes as $x$ increases.\n",
        "\n",
        "**_Exponential Transformation:_**\n",
        "\n",
        "* **Linear-Log Model:** $log(y) = \\beta_0  + \\beta_1 x + ϵ$\n",
        "\n",
        "* * Suitable when $y$ grows exponentially with $x$\n",
        "\n",
        "**_Power Transformation:_**\n",
        "\n",
        "* **Log-Log Model:** $log(y) = \\beta_0  + \\beta_1 log(x) + ϵ$\n",
        "\n",
        "* * Helps when both x and y exhibit exponential growth.\n",
        "\n",
        "**_Square Root Transformation:_**\n",
        "\n",
        "* **Square Root Model:** $y = \\beta_0  + \\beta_1 \\sqrt{x} + ϵ$\n",
        "\n",
        "* * Applied when the variance of $y$ increases with $x$\n",
        "\n",
        "**_Reciprocal Transformation:_**\n",
        "\n",
        "* **Reciprocal Model:**  $y = \\beta_0 + \\beta_1 \\frac{1}{x} + \\epsilon$\n",
        "\n",
        "* * Effective for hyperbolic relationships.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umeFGotquAz4"
      },
      "source": [
        "### Example 11: Data Transformation - Step 2\n",
        "\n",
        "By inspection of **Figure 17.12** you should note that the effect of $x$ on $y$ diminishes as $x$ increases. Looking at the list of possible transformations, it would appear the first one, the _logarithmic transformation:_ would appear to be the most appropiate. In this transformation we use the **_log-linear model:_** $y = \\beta_0  + \\beta_1 log(x) + ϵ$.\n",
        "\n",
        "The code in the cell below transforms the GTP/birth weight data into a log-linear model by plotting the log of x as shown in this code chunk:\n",
        "\n",
        "~~~text\n",
        "# Log transform x\n",
        "log_x = np.log(x)\n",
        "~~~\n",
        "\n",
        "This code recreates **Figure 17.14** on page 418 in your textbook.\n",
        "\n",
        "![____](https://biologicslab.co/BIO5853/images/module_03/lesson_03_9_image46.png)\n",
        "\n",
        "\n",
        "**FIGURE 17.14** Birth rate per 1000 population versus the natural logarithm of GTP per capita"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ri3Br1QBuAz4"
      },
      "outputs": [],
      "source": [
        "# Example 11B: Data Transformation - Step 2\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Extract x- y-values\n",
        "x = np.array(gdpDF['gdp'])\n",
        "y = np.array(gdpDF['birthrt'])\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame({'x': x, 'y': y})\n",
        "\n",
        "# Log transform x\n",
        "log_x = np.log(x)\n",
        "\n",
        "# Create plotting environment\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "# Assign color values\n",
        "color_1 = '#15466d' # Dark blue\n",
        "\n",
        "# Plot scatter plot\n",
        "scatter = ax.scatter(log_x,y, s=20, facecolor='white', edgecolor=color_1)\n",
        "\n",
        "# Set x and y limits\n",
        "#ax.set(xlim=(-5000,200000))\n",
        "ax.set(ylim=(0,50))\n",
        "\n",
        "# Adding labels\n",
        "ax.set_xlabel('Logarithm of GDP per capita',fontsize=12)\n",
        "ax.set_ylabel('Birth rate per 1,000 population',fontsize=12)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FO9jcuXbuAz4"
      },
      "source": [
        "If the code is correct, you should see the following output:\n",
        "\n",
        "![____](https://biologicslab.co/BIO5853/images/module_03/lesson_03_9_image32.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_anOehcuAz4"
      },
      "source": [
        "Note that the relationship between birth rate and the logarithm of GDP appears much more linear than the relationship between birth rate and GDP itself. Therefore, we could fit a simple linear regression model of the form:\n",
        "\n",
        "$$ \\hat{y} = \\hat{\\beta}_0 + \\hat{\\beta}_1 \\ln(x). $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RzeDZTouAz4"
      },
      "source": [
        "## **Lesson Turn-in**\n",
        "\n",
        "When you have completed and run all of the code cells, create a PDF of your notebook and upload the **_PDF_** to your Lesson_03_9 assignment in Canvas for grading.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}