{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bLEEW13uCtiJ"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/DavidSenseman/BIO58533/blob/master/Lesson_01_9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------\n",
    "**COPYRIGHT NOTICE:** This Jupyterlab Notebook is a Derivative work of [Jeff Heaton](https://github.com/jeffheaton) licensed under the Apache License, Version 2.0 (the \"License\"); You may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
    "\n",
    "> [http://www.apache.org/licenses/LICENSE-2.0](http://www.apache.org/licenses/LICENSE-2.0)\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.\n",
    "\n",
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **BIO 5853: Biostatistics**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### **Module 1: Getting Started with Python**\n",
    "\n",
    "* Instructor: [David Senseman](mailto:David.Senseman@utsa.edu), [Department of Integrative Biology](https://sciences.utsa.edu/integrative-biology/), [UTSA](https://www.utsa.edu/)\n",
    "\n",
    "\n",
    "### Module 1 Material\n",
    "\n",
    "* Part 1.1: Course Overview \n",
    "* Part 1.2: Installing Python, Miniconda and Jupyter Lab\n",
    "* Part 1.3: Introduction to Jupyterlab AI, Google CoLab\n",
    "* Part 1.4: Python Basics 1 -- Strings, Variables and Indexing\n",
    "* Part 1.5: Python Basics 2 -- Numbers, Booleans, Operators and Comparisons\n",
    "* Part 1.6: Python Basics 3 -- Lists, Dictionaries, Sets and JSON\n",
    "* Part 1.7: Python Basics 4 -- Conditionals and Loops\n",
    "* Part 1.8: Python Basics 5 -- Packages, Numpy arrays and Matplotlib\n",
    "* **Part 1.9: Python Basics 6 -- Pandas and File Handling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson Setup\n",
    "\n",
    "Run the next code cell to load necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You MUST run this code cell first\n",
    "import os\n",
    "import shutil\n",
    "path = '/'\n",
    "memory = shutil.disk_usage(path)\n",
    "dirpath = os.getcwd()\n",
    "print(\"Your current working directory is : \" + dirpath)\n",
    "print(\"Disk\", memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google CoLab Instructions\n",
    "\n",
    "The following code ensures that Google CoLab is running the correct version of TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "seXFCYH4LDUM",
    "outputId": "c05015aa-871e-4779-9265-5ad07e8bf617",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# You must run this cell second\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "    COLAB = True\n",
    "    print(\"Note: using Google CoLab\")\n",
    "    %tensorflow_version 2.x\n",
    "    import requests\n",
    "    gcloud_token = !gcloud auth print-access-token\n",
    "    gcloud_tokeninfo = requests.get('https://www.googleapis.com/oauth2/v3/tokeninfo?access_token=' + gcloud_token[0]).json()\n",
    "    print(gcloud_tokeninfo['email'])\n",
    "except:\n",
    "    print(\"Note: not using Google CoLab\")\n",
    "    COLAB = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1.9: Python Basics\n",
    "\n",
    "In this lesson we will focus on the software package, Pandas, and on file handling. These two topics naturally go together since the Pandas package includes a number of file handling methods that are frequently used in Python programming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas\n",
    "\n",
    "**_Pandas_** (pronounced as \"PAN-daz\") is a Python package designed for data manipulation and analysis. It provides data structures and operations for manipulating numerical tables and time series. \n",
    "\n",
    "Pandas is built on top of the Numpy package and provides a high-level interface for working with data including data selection, cleaning, filtering, aggregation, and visualization. \n",
    "\n",
    "A central concept in Pandas is the **_DataFrame_**. A Pandas DataFrame is generally the most commonly used Pandas object. \n",
    "\n",
    "A _DataFrame_ is a two-dimensional labeled data structure with columns of potentially different data types (e.g. integers, floats, and strings). They are very similar to an Excel spreadsheet in which each **_row_** represents a single experimental subject or clinical patient and each **_column_** contains a different experimental or clinical measurement from the subject.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Pandas Package\n",
    "\n",
    "Like other Python packages, Pandas has to be _imported_ into a Python program with the following command before it can be used.\n",
    "\n",
    "`import pandas as pd`\n",
    "\n",
    "The normal _alias_ ('nickname') for Pandas is `pd`. When using a method that is part of a Pandas package, the alias `pd` will be used instead of the package name. For example, to use the Pandas `read_csv()` method, the command would be:\n",
    "\n",
    "`pd.read_csv(filename)`\n",
    "\n",
    "Run the next code cell to import `pandas` which is needed for the examples and exercises below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS CODE CELL\n",
    "\n",
    "# Import the package Pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you import a Python package _successfully_ , there is usually no output. \n",
    "\n",
    "If you receive an error it probably means that the package has **not** been previously installed in your current `conda` environment. \n",
    "\n",
    "If you need to install Pandas, uncomment the `conda install` command in the next cell and then run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the next line and run this cell ONLY if you need to install pandas\n",
    "\n",
    "#!conda install pandas -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File handling\n",
    "\n",
    "**_File handling_** in Python is the process of manipulating files and data stored in a file system. This includes reading and writing files, creating and deleting files, accessing metadata about files, and more. \n",
    "\n",
    "Python has a variety of built-in functions to help with file handling, such as the `open()` and `close()` functions for opening and closing files, and the `os module` for interacting with the file system. Additionally, there are several third-party libraries that can be used to simplify file handling, such as the Pandas library for working with tabular data.\n",
    "\n",
    "There are many different types of files that you must be able to process. The two most important file types are listed here:\n",
    "\n",
    "* **CSV files:** (generally have the .csv extension) hold tabular data that resembles spreadsheet data.\n",
    "* **Text files:** (often have the .txt extension) hold unstructured text and are essential for natural language processing.\n",
    "\n",
    "Data can come from a variety of sources. In this class, you will obtain data from three primary locations:\n",
    "\n",
    "* **Your Hard Drive -** This type of data is stored locally, and Python accesses it from a path that looks something like: c:\\data\\myfile.csv. You will download these files from Canvas as part of the lesson in a compressed (Zip) file. \n",
    "* **The Internet -** This type of data resides in the cloud and Python accesses it from a URL that looks something like: https://images.pexels.com/photos/9487467/pexels-photo-9487467.jpeg.\n",
    "* **Google Drive (cloud) -** If your code in Google CoLab, you use GoogleDrive to save and load some data files. CoLab mounts your GoogleDrive into a path similar to the following: /content/drive/My Drive/myfile.csv.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File format of data files\n",
    "\n",
    "Data files can either be **_formatted_** and **_unformatted_**. For example, a Microsoft Word file (.doc or .docx) is a _formatted file_. Microsoft uses a proprietary document format to store MS Word files. If you try to \"read\" a formated file with a simple text editor like Notepad, you would see something unintelligiblelike this:\n",
    "\n",
    "![__](https://biologicslab.co/BIO1173/images/class_01/MSWord.png)\n",
    "\n",
    "Most data files used for statistical processing, are _unformatted_ text files. They can be read with any word processor program or even a simple text editor. \n",
    "\n",
    "For example, the file `iris.txt`, looks like this if you read it with a simple text editor:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~text\n",
    "sepal_l\tsepal_w\tpetal_l\tpetal_w\t species\n",
    "5.1     3.5\t    1.4\t    0.2\t     Iris-setosa\n",
    "4.9\t    3.0\t    1.4\t    0.2\t     Iris-setosa\n",
    "4.7\t    3.2\t    1.3\t    0.2\t     Iris-setosa\n",
    "4.6\t    3.1\t    1.5\t    0.2\t     Iris-setosa\n",
    "5.0\t    3.6\t    1.4\t    0.2\t     Iris-setosa\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File handling with Pandas\n",
    "\n",
    "**_Pandas_** is frequently used in Python programs to read unformated text file. File handling using Pandas typically involves reading in data from a file into a Pandas **_DataFrame_** using the `pd.read_csv(filename)` function. This function can be used to read in data from a variety of sources including CSV files, Excel files, HTML tables, and other formats. \n",
    "\n",
    "The function's name refers to a particularily common file type called a CSV (Comma Separated Values) file. In this file type, a comma **`,`** is used as the **_delimiter_** value, to **separate** one data value from another. \n",
    "\n",
    "Here is what you would see if you read the datafile `iris.csv` with a text editor. In this file, each data value is separated by a comma **`,`** from the next value.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~text\n",
    "sepal_l,sepal_w,petal_l,petal_w,species\n",
    "5.1,3.5,1.4,0.2,Iris-setosa\n",
    "4.9,3.0,1.4,0.2,Iris-setosa\n",
    "4.7,3.2,1.3,0.2,Iris-setosa\n",
    "4.6,3.1,1.5,0.2,Iris-setosa\n",
    "5.0,3.6,1.4,0.2,Iris-setosa\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While a comma **`,`** is often used a the delimited in data text files, it is certainly not the only character used. Other delimiters include a space ` ` or a tab `\\t`. \n",
    "\n",
    "In order to handle txt files with different delimiters, `pd.read_csv(filename)` can take a second argument called `sep` that defines the separator character to use when reading and processing the text file. \n",
    "\n",
    "For example, the following command would be used to read a text file that used a space as a delimiter:\n",
    "\n",
    "`pd.read_csv(filename, sep=' ')`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Read a data file stored on the course HTTPS server\n",
    "\n",
    "The code in the cell below uses the function `pd.read_csv(filename, sep)` to read the data file `iris.txt` stored on the course HTTPS server [https://biologicslab.co](https://biologicslab.co). As the file is read, it is stored in a Pandas DataFrame called `df1`. In the file `iris.txt` a **_tab_** is used as the delimiter. To specify a tab, you use the following: `\\t`.\n",
    "\n",
    "When reading text files with `pd.read_csv()`, it is _always_ a good idea to print out the first 5 rows of data to make sure the read was successful. One way to do this is with the Pandas method `head()` as demonstrated in the example below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Example 1: Use pd.read_csv to read a file on the hard drive \n",
    "\n",
    "# Read local data file using Pandas read_csv() function\n",
    "df1 = pd.read_csv(\"https://biologicslab.co/BIO5853/data/iris.txt\", \n",
    "                   sep='\\t')  # define the separator as a tab\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_rows', 6)\n",
    "pd.set_option('display.max_columns', 9)\n",
    "\n",
    "# Print out the first 5 records using the head() method\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see the following table:\n",
    "\n",
    "![____](https://biologicslab.co/BIO1173/images/class_01/class_01_9_iris.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 1: Read a data file stored on the course HTTPS server**\n",
    "\n",
    "In the cell below, use the Pandas `pd.read_csv(filename, sep)` function to read the data file `Pima.txt` on your hard drive and store the data in a new data frame called `df2`. Use the `head()` method to print out the first 5 records in `df2`. \n",
    "\n",
    "IMPORTANT: The deliminter in this file a comma. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code for Exercise 1 here \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see the following output:\n",
    "\n",
    "![__](https://biologicslab.co/BIO1173/images/class_01/Pima.png)\n",
    "\n",
    "However, if you used the **wrong** delimiter, you will see this instead.\n",
    "\n",
    "![__](https://biologicslab.co/BIO1173/images/class_01/PimaWrong.png)\n",
    "\n",
    "If you see the second image, you need to change the value of the delimiter to a comma. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Use the Pandas `display()` function. \n",
    "\n",
    "Similar to the `head()` function, the Pandas `display()` function is another convenient way to view data in a DataFrame. It is used to quickly display the contents of a DataFrame especially in an interactive environments such as JupyterLab. It is quite useful for quickly analyzing data and it allows the user to have more control over the way the data is displayed.\n",
    "\n",
    "The code in the cell below shows how to use this method with the Iris data stores in `df1`. Since the `display()` function allows you to control the maximum rows and columns to show, it can provide a cleaner display than merely printing a DataFrame with many columns and/or rows that using the `head()` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Example 2: Use display method\n",
    "\n",
    "# Set max columns and max rows\n",
    "pd.set_option('display.max_columns', 4)\n",
    "pd.set_option('display.max_rows', 6)\n",
    "\n",
    "# Display 4 columns and 6 rows\n",
    "display(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see the following table:\n",
    "\n",
    "![____](https://biologicslab.co/BIO1173/images/class_01/class_01_9_display.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 2: Use the Pandas display() function.**\n",
    "\n",
    "In the cell below, use the Pandas `display()` function to print a maximum of 8 columns and 8 rows of the DataFrame `df2`.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Insert your code for Exercise 2 here \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "If your code is correct you should see the following output:\n",
    "\n",
    "![__](https://biologicslab.co/BIO1173/images/class_01/PDdisplay.png)\n",
    "\n",
    "However, if you used the **wrong** delimiter in **Exercise 2**, you will see this instead.\n",
    "\n",
    "![__](https://biologicslab.co/BIO1173/images/class_01/PDdisplayWrong.png)\n",
    "\n",
    "### **If you see the wrong display --STOP**\n",
    "\n",
    "The reason that you are seeing the wrong display is that you still haven't changed the delimiter value in **Exercise 2**. Go back to **Exercise 2** and change the delimiter to be a comma `sep=','` and then **_re-run_** the Exercise 2 code cell.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3: Use the Pandas `describe()` method. \n",
    "\n",
    "With any new dataset, it is generally useful to get a quick, overall view of dataset's contents using the Pandas `describe()` method.  \n",
    "\n",
    "The `descibe()` method returns an variety of summary statistics about the data, including the count, mean, standard deviation, minimum, maximum, and first and third quartiles. It also includes a count of the number of non-null values, and the percent of the data that is missing. This information can be used to get a better understanding of the data and its distributions.\n",
    "\n",
    "The code in the cell below shows how to use this method with the Iris data stores in `df1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Example 3: Use describe() method to print summary statistics\n",
    "\n",
    "# Set max columns and max rows\n",
    "pd.set_option('display.max_columns', 8)\n",
    "pd.set_option('display.max_rows', 8)\n",
    "\n",
    "# Describe() method with df1\n",
    "df1.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see the following table:\n",
    "\n",
    "![____](https://biologicslab.co/BIO1173/images/class_01/class_01_9_describe.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing to notice is that the **count** values are not the same for all the columns. In particular, the count for the column `petal_w`is `149`, while the count for all the other columns is 150. \n",
    "\n",
    "The `describe()` method excludes any NA or missing values which suggests that there is a missing value in the `petal_w` column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 3: Use the Pandas `describe()` method.**\n",
    "\n",
    "In the cell below, use the Pandas `describe()` method to print the summary statistics of the data in `df2`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code for Exercise 3 here \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see the following output:\n",
    "\n",
    "![___](https://biologicslab.co/BIO1173/images/class_01/Describe.png)\n",
    "\n",
    "Look at the **count** values to see if there are any missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values\n",
    "\n",
    "Missing values are a reality of machine learning.  Ideally, every row of data will have values for all columns.  However, this is rarely the case. Replacing missing values is important in machine learning they can cause problems with the model's accuracy and can lead to incorrect predictions. It is up to you to **_clean your data_**  \n",
    "\n",
    "There are a few different ways to deal with missing data. You could simply delete any record (i.e. the entire row) if it contained one (or more) missing value(s). This may or may not be reasonable depending up the data set and the number of missing values in it.\n",
    "\n",
    "An alternative approach is to replace missing value(s) with the **_median value_** for that column. Here is the Wiki page for the program that calculates the [median](https://en.wikipedia.org/wiki/Median).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 4: Use the Pandas `isnull()` method to find missing values. \n",
    "\n",
    "When working with a new dataset you should perform a quick check for any missing values. The example below, the Pandas method `isnull()` is used to locate any missing values in the Iris data stored in `df1`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 4: Use isnull() method to find missing data\n",
    "\n",
    "# Find the locations of missing data\n",
    "missing_locations = df1.isnull().any()\n",
    "\n",
    "# Display the locations of missing data\n",
    "print(missing_locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see the following output:\n",
    "~~~text\n",
    "sepal_l    False\n",
    "sepal_w    False\n",
    "petal_l    False\n",
    "petal_w     True\n",
    "species    False\n",
    "dtype: bool\n",
    "~~~\n",
    "The output says there is at least one (and possibly more) missing values in the column `petal_w`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 4: Use the Pandas `isnull()` method to find missing values.**\n",
    "\n",
    "In the cell below, use the Pandas `isnull()` method to locate any missing values in `df2`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code for Exercise 4 here \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see the following output:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~text\n",
    "npreg    False\n",
    "glu      False\n",
    "bp       False\n",
    "skin     False\n",
    "bmi       True\n",
    "ped      False\n",
    "age      False\n",
    "type     False\n",
    "dtype: bool\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output reports that there is at least one and possibly more missing values in the column `bmi`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 5: Use the Pandas `fillna()` method to replace missing values. \n",
    "\n",
    "Now that the location of the missing value(s) has been determined, the Pandas method `fillna()` can now be use to replace the missing values.  \n",
    "\n",
    "The first step is to compute the `median` value for the column using the Pandas method `median()`. The next step is to use the Pandas method `fillna()` to replace any missing values in the `petal_w` column with the median value. Finally, we check once more for any missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 5: Use isnull() method to find missing data\n",
    "\n",
    "# Find the median of the column petal_w\n",
    "PWidth_med = df1['petal_w'].median()\n",
    "\n",
    "# Print out the median value\n",
    "print(f\"The median value = {PWidth_med} for petal width.\")\n",
    "print(f\"Replacing missing values with {PWidth_med}.\")\n",
    "\n",
    "# Use fillna method\n",
    "df1['petal_w'] = df1['petal_w'].fillna(PWidth_med)\n",
    "\n",
    "# Find the locations of missing data\n",
    "print(\"\\nLooking for missing values...\")  # The \\n means print a newline\n",
    "missing_locations = df1.isnull().any()\n",
    "\n",
    "# Display the locations of missing data\n",
    "print(missing_locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see the following output:\n",
    "~~~text\n",
    "The median value = 1.3 for petal width.\n",
    "Replacing missing values with 1.3.\n",
    "\n",
    "Looking for missing values...\n",
    "sepal_l    False\n",
    "sepal_w    False\n",
    "petal_l    False\n",
    "petal_w    False\n",
    "species    False\n",
    "dtype: bool\n",
    "~~~\n",
    "The output says there are no longer any missing values in any column. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 5: Use the Pandas `fillna()` method to replace missing values**\n",
    "\n",
    "In the cell below, use the Pandas `isnull()` method to locate any missing values in `df2`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code for Exercise 5 here \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see the following output:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~text\n",
    "The median value = 32.8 for bmi.\n",
    "Replacing missing values with 32.8.\n",
    "\n",
    "Looking for missing values...\n",
    "npreg    False\n",
    "glu      False\n",
    "bp       False\n",
    "skin     False\n",
    "bmi      False\n",
    "ped      False\n",
    "age      False\n",
    "type     False\n",
    "dtype: bool\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output above reports that there are no more missing values in any column. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 6: Use the Pandas `copy()` method to create a copy of a data frame. \n",
    "\n",
    "The Pandas `copy()` method is used to create a **_shallow copy_** of a DataFrame. A shallow copy of a DataFrame is a copy that does _not_ contain a deep copy of the objects or data within the DataFrame. Instead, it creates a new object with references to the objects or data in the original DataFrame. In other words, if the original DataFrame is changed, the shallow copy will **_not_** be affected.  \n",
    "\n",
    "You might want to use a shallow copy of a DataFrame when you need to make changes to the DataFrame without affecting the original data. Shallow copies are often used when you need to make temporary changes to DataFrame and then revert back to the original. \n",
    "\n",
    "The code in the cell below creates a shallow copy of the DataFrame `df1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Example 6: Use the `copy()` method to make a shallow copy\n",
    "\n",
    "# Make shallow copy\n",
    "df1_copy = df1.copy()\n",
    "\n",
    "# Show the first records in the copy\n",
    "df1_copy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see the following table:\n",
    "\n",
    "![____](https://biologicslab.co/BIO1173/images/class_01/class_01_9_Exm6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 6: Use the Pandas `copy()` method to create a copy of a data frame**. \n",
    "\n",
    "In the cell below write the code to create a shallow copy of the DataFrame `df2`. Call your copy `df2_copy`. Print out the first 5 records in `df2_copy` using the `head()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code for Exercise 6 here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see the following output:\n",
    "\n",
    "![_](https://biologicslab.co/BIO1173/images/class_01/Pima.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping field in a Pandas data frame\n",
    "\n",
    "**_Dropping a field_** in a Pandas DataFrame is a way of removing a column from the dataset. This can be done using the Panda `drop()` method, which takes the label of the column that you want to remove. You may want to do this if the field is irrelevant to the analysis you are performing, or if it contains redundant information. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 7: Use the Pandas `drop()` method to drop a field in a DataFrame. \n",
    "\n",
    "The code in the cell below uses the Pandas `drop()` method is used to drop the field `species` from the Iris data set. To preserve the original data, the `drop()` method will be used with the shallow copy created in **Example 6**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 7: Drop a field in a data frame using drop() method \n",
    "\n",
    "# Print the column names before dropping\n",
    "print(f\"Before drop: {list(df1_copy.columns)}\")\n",
    "\n",
    "# Use the drop method to drop the species column\n",
    "df1_copy.drop(columns=['species'], inplace=True)\n",
    "\n",
    "# Print out the columns after the drop\n",
    "print(f\"After drop: {list(df1_copy.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the code is correct your should see:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~text\n",
    "Before drop: ['sepal_l', 'sepal_w', 'petal_l', 'petal_w', 'species']\n",
    "After drop: ['sepal_l', 'sepal_w', 'petal_l', 'petal_w']\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if you see the following error:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~text\n",
    "KeyError: \"['species'] not found in axis\"\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it probably means that you have run the example already so that `df1_copy` no longer contains the column `species`. This is one reason to make a backup copy when you are making changes to a data frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 7: Use the Pandas `drop()` method to drop a field in a DataFrame.** \n",
    "\n",
    "In the cell below use the Pandas `drop()` method to drop the `type` column from the **_copy_** of the Pima data stored in `df2_copy`. Print the column names before and after dropping the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code for Exercise 7 here \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see the following output:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~text\n",
    "Before drop: ['npreg', 'glu', 'bp', 'skin', 'bmi', 'ped', 'age', 'type']\n",
    "After drop: ['npreg', 'glu', 'bp', 'skin', 'bmi', 'ped', 'age']\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if you see the following error:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~text\n",
    "KeyError: \"['type'] not found in axis\"\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it probably means that you have run the example already so that `df2_copy` no longer contains the column `type`. To get rid of this errow you will need to re-run **Exercise 6** to create a new copy of `df2_copy` and then re-run **Exercise 7** using the new copy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 8: Use Pandas `map()` method to map strings to integer values\n",
    "\n",
    "Mapping string values to integer values can be important when using certain machine learning models. Some machine learning algorithms do not work well with string values, so they must be converted to integer values. This is done by assigning a unique number to each distinct string value. This helps the machine learning algorithm to recognize patterns in the data and make more accurate predictions.\n",
    "\n",
    "In this example, the column `species` in the Iris flower data set will have the following string values mapped to the following integers:\n",
    "\n",
    "* Iris-setosa: mapped to the value 0\n",
    "* Iris-versicolor: mapped to the value 1\n",
    "* Iris-virginica: mapped to the value 2\n",
    "\n",
    "using the Pandas `map()` method. \n",
    "\n",
    "The code starts by making a new, shallow copy of the `df1` data frame, called `df1_copy`, for the remapping. This keeps intact the original Iris data stored in `df1`.\n",
    "\n",
    "The code then set the display options so that the values of the `species` column can be more easily observed. Many data sets used in machine learning can have too many columns as well as too many rows to easily display in a Jupyter Lab notebook.\n",
    "\n",
    "To verify that the mapping worked as expected, the contents of the `df_copy` data frame are printed out before, and after, the mapping using the `display()` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Example 8: Map strings to integers \n",
    "\n",
    "# Make a new copy of df1\n",
    "df1_copy = df1.copy()\n",
    "\n",
    "# Set max columns and max rows\n",
    "pd.set_option('display.max_columns', 4)\n",
    "pd.set_option('display.max_rows', 6)\n",
    "\n",
    "# Describe() method with df2\n",
    "print(\"Iris data before mapping:\")\n",
    "display(df1_copy)\n",
    "\n",
    "# Define the mapping dictionary\n",
    "mapping = {'Iris-setosa': 0, 'Iris-versicolor': 1, 'Iris-virginica' :2}\n",
    "\n",
    "# Map the integer column to strings\n",
    "df1_copy['species'] = df1_copy['species'].map(mapping)\n",
    "\n",
    "print(\"Iris data after mapping:\")\n",
    "display(df1_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see the following output:\n",
    "\n",
    "![_](https://biologicslab.co/BIO1173/images/class_01/class_01_9_Exm9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should notice that the species names have been converted in `0` for Iris-setosa and `2` for Iris-virginica, in the `species` column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 8: Use Pandas `map()` method to map strings to integer values**\n",
    "\n",
    "In the cell below, use the Pandas `map()` method to map string values in the column `type` from `No` to 0, and `Yes` to 1. \n",
    "\n",
    "Start by making a new copy of `df2` and call it `df2_copy`. Perform the mapping on the `df2_copy` data frame. As in **Example 8**, use the Pandas `display()` function to print out 4 columns and 6 row of `df2_copy` before and after the mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Insert your code for Exercise 8 here \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see the following output:\n",
    "\n",
    "![_](https://biologicslab.co/BIO1173/images/class_01/class_01_9_Exe9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output above shows that the string values, `Yes` and `No` in the `type` column have been converted to the integer values `0` and `1` respectively. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Pandas DataFrame to a Numpy array\n",
    "\n",
    "Pandas has a built-in function called `to_numpy()` which can be used to convert a Pandas DataFrame or series to Numpy array. This can be useful for manipulating or plotting data using Numpy functions. \n",
    "\n",
    "The `to_numpy()` function takes no arguments and returns a Numpy array containing the data from the Pandas DataFrame or series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 9: Use Pandas `to_numpy()` method to convert a DataFrame into Numpy array\n",
    "\n",
    "The code in the cell below uses the `to_numpy()` method to covert the Iris data stored in the `df1` DataFrame, into a Numpy array called `dft_ar`. It then uses square bracket indexing to print out the first 5 rows of the new Numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Example 9: Convert data frame to numpy array \n",
    "\n",
    "# Use the to_numpy method\n",
    "df1_ar = df1.to_numpy()\n",
    "\n",
    "# Print the first 5 rows of the numpy array\n",
    "print(df1_ar[ :5, ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see the following output:\n",
    "~~~text\n",
    "[[5.1 3.5 1.4 0.2 'Iris-setosa']\n",
    " [4.9 3.0 1.4 0.2 'Iris-setosa']\n",
    " [4.7 3.2 1.3 0.2 'Iris-setosa']\n",
    " [4.6 3.1 1.5 0.2 'Iris-setosa']\n",
    " [5.0 3.6 1.4 0.2 'Iris-setosa']]\n",
    "~~~\n",
    "You should notice that the `to_numpy()` converted both the numerical values as well as the strings in the `species` column to the new array. While arrays generally contain the same data type (e.g. all numbers or all strings), Numpy arrays can contain both data types. However, a Numpy array is very different than a Dataframe. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 9: Use Pandas `to_numpy()` method to convert a DataFrame into Numpy array**\n",
    "\n",
    "In the cell below, use the Pandas `to_numpy()` method to convert the Pima data stored in `df2` into a new Numpy array called `df2_ar`. Print out the first 10 rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code for Exercise 9 here \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct you should see the following output:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~text\n",
    "[[5 86 68 28 30.2 0.364 24 'No']\n",
    " [7 195 70 33 25.1 0.163 55 'Yes']\n",
    " [5 77 82 41 35.8 0.156 35 'No']\n",
    " [0 165 76 43 47.9 0.259 26 'No']\n",
    " [0 107 60 25 26.4 0.133 23 'No']\n",
    " [5 97 76 27 35.6 0.378 52 'Yes']\n",
    " [3 83 58 31 34.3 0.336 25 'No']\n",
    " [1 193 50 16 25.9 0.655 24 'No']\n",
    " [3 142 80 15 32.4 0.2 63 'No']\n",
    " [2 128 78 37 43.3 1.224 31 'Yes']]\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should notice that when you generate a Numpy array, you lose the column headers (titles) that are present in the DataFrame as well as the sequential index values at the left."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Lesson Turn-in**\n",
    "\n",
    "When you have completed all of the code cells, and run them in sequential order (the last code cell should be number 22), use the **File --> Print.. --> Save to PDF** to generate a PDF of your JupyterLab notebook. Save your PDF as `Lesson_01_9.lastname.pdf` where _lastname_ is your last name, and upload the file to Canvas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (biostats)",
   "language": "python",
   "name": "biostats"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
